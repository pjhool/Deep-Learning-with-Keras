{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjhool/Deep-Learning-with-Keras/blob/master/Chapter01/Mnist_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bIZjpFVXuHoS",
        "colab_type": "code",
        "outputId": "3b8604bc-6c71-4cbd-bb1a-f118790c5721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7687
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "np.random.seed(1671)  # for reproducibility\n",
        "\n",
        "# network and training\n",
        "NB_EPOCH = 200\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "OPTIMIZER = SGD() # SGD optimizer, explained later in this chapter\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# data: shuffled and split between train and test sets\n",
        "#\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalize \n",
        "#\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/200\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 1.3633 - acc: 0.6796 - val_loss: 0.8904 - val_acc: 0.8246\n",
            "Epoch 2/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.7913 - acc: 0.8272 - val_loss: 0.6572 - val_acc: 0.8546\n",
            "Epoch 3/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.6436 - acc: 0.8497 - val_loss: 0.5625 - val_acc: 0.8681\n",
            "Epoch 4/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.5717 - acc: 0.8602 - val_loss: 0.5098 - val_acc: 0.8765\n",
            "Epoch 5/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.5276 - acc: 0.8678 - val_loss: 0.4758 - val_acc: 0.8826\n",
            "Epoch 6/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.4973 - acc: 0.8726 - val_loss: 0.4515 - val_acc: 0.8866\n",
            "Epoch 7/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.4748 - acc: 0.8775 - val_loss: 0.4333 - val_acc: 0.8882\n",
            "Epoch 8/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.4574 - acc: 0.8803 - val_loss: 0.4189 - val_acc: 0.8920\n",
            "Epoch 9/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.4433 - acc: 0.8834 - val_loss: 0.4075 - val_acc: 0.8939\n",
            "Epoch 10/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.4317 - acc: 0.8850 - val_loss: 0.3977 - val_acc: 0.8966\n",
            "Epoch 11/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.4218 - acc: 0.8873 - val_loss: 0.3896 - val_acc: 0.8984\n",
            "Epoch 12/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.4134 - acc: 0.8888 - val_loss: 0.3827 - val_acc: 0.8995\n",
            "Epoch 13/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.4060 - acc: 0.8902 - val_loss: 0.3766 - val_acc: 0.9003\n",
            "Epoch 14/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3995 - acc: 0.8918 - val_loss: 0.3712 - val_acc: 0.9013\n",
            "Epoch 15/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3936 - acc: 0.8928 - val_loss: 0.3664 - val_acc: 0.9016\n",
            "Epoch 16/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3884 - acc: 0.8945 - val_loss: 0.3621 - val_acc: 0.9031\n",
            "Epoch 17/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3837 - acc: 0.8950 - val_loss: 0.3582 - val_acc: 0.9033\n",
            "Epoch 18/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3794 - acc: 0.8962 - val_loss: 0.3546 - val_acc: 0.9039\n",
            "Epoch 19/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3755 - acc: 0.8970 - val_loss: 0.3514 - val_acc: 0.9048\n",
            "Epoch 20/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3718 - acc: 0.8979 - val_loss: 0.3485 - val_acc: 0.9053\n",
            "Epoch 21/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3685 - acc: 0.8985 - val_loss: 0.3457 - val_acc: 0.9058\n",
            "Epoch 22/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3653 - acc: 0.8995 - val_loss: 0.3431 - val_acc: 0.9058\n",
            "Epoch 23/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3625 - acc: 0.8999 - val_loss: 0.3407 - val_acc: 0.9063\n",
            "Epoch 24/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3598 - acc: 0.9008 - val_loss: 0.3385 - val_acc: 0.9070\n",
            "Epoch 25/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3572 - acc: 0.9012 - val_loss: 0.3364 - val_acc: 0.9074\n",
            "Epoch 26/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3548 - acc: 0.9019 - val_loss: 0.3345 - val_acc: 0.9084\n",
            "Epoch 27/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3525 - acc: 0.9022 - val_loss: 0.3326 - val_acc: 0.9082\n",
            "Epoch 28/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3504 - acc: 0.9032 - val_loss: 0.3311 - val_acc: 0.9090\n",
            "Epoch 29/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.3484 - acc: 0.9031 - val_loss: 0.3293 - val_acc: 0.9094\n",
            "Epoch 30/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3465 - acc: 0.9041 - val_loss: 0.3277 - val_acc: 0.9097\n",
            "Epoch 31/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3447 - acc: 0.9044 - val_loss: 0.3264 - val_acc: 0.9097\n",
            "Epoch 32/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3430 - acc: 0.9047 - val_loss: 0.3249 - val_acc: 0.9097\n",
            "Epoch 33/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3413 - acc: 0.9051 - val_loss: 0.3235 - val_acc: 0.9103\n",
            "Epoch 34/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3397 - acc: 0.9056 - val_loss: 0.3222 - val_acc: 0.9104\n",
            "Epoch 35/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3382 - acc: 0.9058 - val_loss: 0.3211 - val_acc: 0.9110\n",
            "Epoch 36/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3368 - acc: 0.9062 - val_loss: 0.3198 - val_acc: 0.9110\n",
            "Epoch 37/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3353 - acc: 0.9069 - val_loss: 0.3187 - val_acc: 0.9117\n",
            "Epoch 38/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3340 - acc: 0.9075 - val_loss: 0.3177 - val_acc: 0.9120\n",
            "Epoch 39/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3327 - acc: 0.9075 - val_loss: 0.3166 - val_acc: 0.9122\n",
            "Epoch 40/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3314 - acc: 0.9078 - val_loss: 0.3159 - val_acc: 0.9118\n",
            "Epoch 41/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3303 - acc: 0.9080 - val_loss: 0.3147 - val_acc: 0.9127\n",
            "Epoch 42/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3291 - acc: 0.9084 - val_loss: 0.3138 - val_acc: 0.9132\n",
            "Epoch 43/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3280 - acc: 0.9089 - val_loss: 0.3130 - val_acc: 0.9132\n",
            "Epoch 44/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3270 - acc: 0.9091 - val_loss: 0.3121 - val_acc: 0.9132\n",
            "Epoch 45/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3259 - acc: 0.9093 - val_loss: 0.3113 - val_acc: 0.9135\n",
            "Epoch 46/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3249 - acc: 0.9095 - val_loss: 0.3105 - val_acc: 0.9137\n",
            "Epoch 47/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3239 - acc: 0.9105 - val_loss: 0.3098 - val_acc: 0.9141\n",
            "Epoch 48/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3230 - acc: 0.9105 - val_loss: 0.3090 - val_acc: 0.9146\n",
            "Epoch 49/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3221 - acc: 0.9102 - val_loss: 0.3083 - val_acc: 0.9151\n",
            "Epoch 50/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3212 - acc: 0.9109 - val_loss: 0.3075 - val_acc: 0.9150\n",
            "Epoch 51/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3204 - acc: 0.9109 - val_loss: 0.3070 - val_acc: 0.9150\n",
            "Epoch 52/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3195 - acc: 0.9112 - val_loss: 0.3063 - val_acc: 0.9148\n",
            "Epoch 53/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3187 - acc: 0.9114 - val_loss: 0.3057 - val_acc: 0.9153\n",
            "Epoch 54/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3180 - acc: 0.9117 - val_loss: 0.3050 - val_acc: 0.9148\n",
            "Epoch 55/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3171 - acc: 0.9121 - val_loss: 0.3044 - val_acc: 0.9149\n",
            "Epoch 56/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3164 - acc: 0.9121 - val_loss: 0.3037 - val_acc: 0.9156\n",
            "Epoch 57/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3157 - acc: 0.9128 - val_loss: 0.3034 - val_acc: 0.9152\n",
            "Epoch 58/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3149 - acc: 0.9121 - val_loss: 0.3029 - val_acc: 0.9148\n",
            "Epoch 59/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3143 - acc: 0.9128 - val_loss: 0.3022 - val_acc: 0.9151\n",
            "Epoch 60/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3136 - acc: 0.9129 - val_loss: 0.3016 - val_acc: 0.9161\n",
            "Epoch 61/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3130 - acc: 0.9133 - val_loss: 0.3011 - val_acc: 0.9158\n",
            "Epoch 62/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3123 - acc: 0.9131 - val_loss: 0.3007 - val_acc: 0.9151\n",
            "Epoch 63/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3117 - acc: 0.9136 - val_loss: 0.3003 - val_acc: 0.9156\n",
            "Epoch 64/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3110 - acc: 0.9137 - val_loss: 0.2997 - val_acc: 0.9158\n",
            "Epoch 65/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3105 - acc: 0.9137 - val_loss: 0.2992 - val_acc: 0.9159\n",
            "Epoch 66/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3098 - acc: 0.9138 - val_loss: 0.2988 - val_acc: 0.9161\n",
            "Epoch 67/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3093 - acc: 0.9141 - val_loss: 0.2983 - val_acc: 0.9165\n",
            "Epoch 68/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3087 - acc: 0.9139 - val_loss: 0.2979 - val_acc: 0.9166\n",
            "Epoch 69/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3082 - acc: 0.9144 - val_loss: 0.2976 - val_acc: 0.9164\n",
            "Epoch 70/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3077 - acc: 0.9145 - val_loss: 0.2971 - val_acc: 0.9166\n",
            "Epoch 71/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3071 - acc: 0.9146 - val_loss: 0.2967 - val_acc: 0.9172\n",
            "Epoch 72/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3066 - acc: 0.9147 - val_loss: 0.2964 - val_acc: 0.9167\n",
            "Epoch 73/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3061 - acc: 0.9151 - val_loss: 0.2960 - val_acc: 0.9169\n",
            "Epoch 74/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.3056 - acc: 0.9150 - val_loss: 0.2956 - val_acc: 0.9173\n",
            "Epoch 75/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.3051 - acc: 0.9151 - val_loss: 0.2952 - val_acc: 0.9177\n",
            "Epoch 76/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.3046 - acc: 0.9152 - val_loss: 0.2950 - val_acc: 0.9173\n",
            "Epoch 77/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3042 - acc: 0.9154 - val_loss: 0.2945 - val_acc: 0.9172\n",
            "Epoch 78/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3037 - acc: 0.9154 - val_loss: 0.2942 - val_acc: 0.9176\n",
            "Epoch 79/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3032 - acc: 0.9157 - val_loss: 0.2939 - val_acc: 0.9179\n",
            "Epoch 80/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3028 - acc: 0.9156 - val_loss: 0.2936 - val_acc: 0.9177\n",
            "Epoch 81/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3024 - acc: 0.9157 - val_loss: 0.2933 - val_acc: 0.9179\n",
            "Epoch 82/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3019 - acc: 0.9157 - val_loss: 0.2930 - val_acc: 0.9178\n",
            "Epoch 83/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3015 - acc: 0.9160 - val_loss: 0.2926 - val_acc: 0.9182\n",
            "Epoch 84/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3011 - acc: 0.9161 - val_loss: 0.2924 - val_acc: 0.9179\n",
            "Epoch 85/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.3007 - acc: 0.9165 - val_loss: 0.2920 - val_acc: 0.9184\n",
            "Epoch 86/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.3003 - acc: 0.9164 - val_loss: 0.2918 - val_acc: 0.9185\n",
            "Epoch 87/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2999 - acc: 0.9165 - val_loss: 0.2914 - val_acc: 0.9185\n",
            "Epoch 88/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2995 - acc: 0.9166 - val_loss: 0.2911 - val_acc: 0.9188\n",
            "Epoch 89/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2991 - acc: 0.9167 - val_loss: 0.2909 - val_acc: 0.9191\n",
            "Epoch 90/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2988 - acc: 0.9169 - val_loss: 0.2906 - val_acc: 0.9191\n",
            "Epoch 91/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2984 - acc: 0.9168 - val_loss: 0.2903 - val_acc: 0.9192\n",
            "Epoch 92/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2981 - acc: 0.9170 - val_loss: 0.2901 - val_acc: 0.9196\n",
            "Epoch 93/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2977 - acc: 0.9171 - val_loss: 0.2898 - val_acc: 0.9195\n",
            "Epoch 94/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2973 - acc: 0.9172 - val_loss: 0.2895 - val_acc: 0.9196\n",
            "Epoch 95/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2970 - acc: 0.9174 - val_loss: 0.2894 - val_acc: 0.9196\n",
            "Epoch 96/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2967 - acc: 0.9174 - val_loss: 0.2891 - val_acc: 0.9198\n",
            "Epoch 97/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2963 - acc: 0.9176 - val_loss: 0.2889 - val_acc: 0.9197\n",
            "Epoch 98/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2960 - acc: 0.9174 - val_loss: 0.2886 - val_acc: 0.9202\n",
            "Epoch 99/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2957 - acc: 0.9176 - val_loss: 0.2884 - val_acc: 0.9202\n",
            "Epoch 100/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2953 - acc: 0.9178 - val_loss: 0.2882 - val_acc: 0.9200\n",
            "Epoch 101/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2950 - acc: 0.9179 - val_loss: 0.2879 - val_acc: 0.9201\n",
            "Epoch 102/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2947 - acc: 0.9180 - val_loss: 0.2877 - val_acc: 0.9204\n",
            "Epoch 103/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2944 - acc: 0.9180 - val_loss: 0.2875 - val_acc: 0.9202\n",
            "Epoch 104/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2941 - acc: 0.9184 - val_loss: 0.2873 - val_acc: 0.9202\n",
            "Epoch 105/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2938 - acc: 0.9183 - val_loss: 0.2871 - val_acc: 0.9206\n",
            "Epoch 106/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2935 - acc: 0.9183 - val_loss: 0.2868 - val_acc: 0.9202\n",
            "Epoch 107/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2932 - acc: 0.9186 - val_loss: 0.2867 - val_acc: 0.9206\n",
            "Epoch 108/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2929 - acc: 0.9185 - val_loss: 0.2864 - val_acc: 0.9208\n",
            "Epoch 109/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2927 - acc: 0.9185 - val_loss: 0.2863 - val_acc: 0.9206\n",
            "Epoch 110/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2923 - acc: 0.9187 - val_loss: 0.2860 - val_acc: 0.9204\n",
            "Epoch 111/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2921 - acc: 0.9184 - val_loss: 0.2858 - val_acc: 0.9210\n",
            "Epoch 112/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2918 - acc: 0.9187 - val_loss: 0.2857 - val_acc: 0.9207\n",
            "Epoch 113/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2915 - acc: 0.9189 - val_loss: 0.2854 - val_acc: 0.9210\n",
            "Epoch 114/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.2913 - acc: 0.9188 - val_loss: 0.2853 - val_acc: 0.9211\n",
            "Epoch 115/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2910 - acc: 0.9189 - val_loss: 0.2852 - val_acc: 0.9205\n",
            "Epoch 116/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2908 - acc: 0.9189 - val_loss: 0.2849 - val_acc: 0.9213\n",
            "Epoch 117/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2905 - acc: 0.9193 - val_loss: 0.2847 - val_acc: 0.9213\n",
            "Epoch 118/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2902 - acc: 0.9192 - val_loss: 0.2846 - val_acc: 0.9212\n",
            "Epoch 119/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2900 - acc: 0.9191 - val_loss: 0.2844 - val_acc: 0.9212\n",
            "Epoch 120/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2898 - acc: 0.9192 - val_loss: 0.2842 - val_acc: 0.9212\n",
            "Epoch 121/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2895 - acc: 0.9191 - val_loss: 0.2841 - val_acc: 0.9212\n",
            "Epoch 122/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2892 - acc: 0.9192 - val_loss: 0.2840 - val_acc: 0.9212\n",
            "Epoch 123/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2890 - acc: 0.9194 - val_loss: 0.2838 - val_acc: 0.9211\n",
            "Epoch 124/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2888 - acc: 0.9197 - val_loss: 0.2837 - val_acc: 0.9210\n",
            "Epoch 125/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2885 - acc: 0.9193 - val_loss: 0.2835 - val_acc: 0.9207\n",
            "Epoch 126/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2883 - acc: 0.9197 - val_loss: 0.2834 - val_acc: 0.9217\n",
            "Epoch 127/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2881 - acc: 0.9194 - val_loss: 0.2832 - val_acc: 0.9212\n",
            "Epoch 128/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2879 - acc: 0.9194 - val_loss: 0.2830 - val_acc: 0.9210\n",
            "Epoch 129/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2876 - acc: 0.9196 - val_loss: 0.2828 - val_acc: 0.9217\n",
            "Epoch 130/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2874 - acc: 0.9197 - val_loss: 0.2826 - val_acc: 0.9216\n",
            "Epoch 131/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2871 - acc: 0.9200 - val_loss: 0.2827 - val_acc: 0.9211\n",
            "Epoch 132/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2870 - acc: 0.9197 - val_loss: 0.2824 - val_acc: 0.9213\n",
            "Epoch 133/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2868 - acc: 0.9198 - val_loss: 0.2823 - val_acc: 0.9216\n",
            "Epoch 134/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2866 - acc: 0.9199 - val_loss: 0.2822 - val_acc: 0.9214\n",
            "Epoch 135/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2863 - acc: 0.9203 - val_loss: 0.2820 - val_acc: 0.9213\n",
            "Epoch 136/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2861 - acc: 0.9196 - val_loss: 0.2818 - val_acc: 0.9215\n",
            "Epoch 137/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2859 - acc: 0.9198 - val_loss: 0.2818 - val_acc: 0.9217\n",
            "Epoch 138/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2857 - acc: 0.9203 - val_loss: 0.2815 - val_acc: 0.9218\n",
            "Epoch 139/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2855 - acc: 0.9203 - val_loss: 0.2814 - val_acc: 0.9215\n",
            "Epoch 140/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2853 - acc: 0.9201 - val_loss: 0.2812 - val_acc: 0.9216\n",
            "Epoch 141/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2852 - acc: 0.9204 - val_loss: 0.2811 - val_acc: 0.9217\n",
            "Epoch 142/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2849 - acc: 0.9201 - val_loss: 0.2810 - val_acc: 0.9217\n",
            "Epoch 143/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2848 - acc: 0.9205 - val_loss: 0.2809 - val_acc: 0.9219\n",
            "Epoch 144/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2846 - acc: 0.9208 - val_loss: 0.2808 - val_acc: 0.9217\n",
            "Epoch 145/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2844 - acc: 0.9207 - val_loss: 0.2806 - val_acc: 0.9221\n",
            "Epoch 146/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2841 - acc: 0.9206 - val_loss: 0.2806 - val_acc: 0.9220\n",
            "Epoch 147/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2840 - acc: 0.9207 - val_loss: 0.2804 - val_acc: 0.9217\n",
            "Epoch 148/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.2838 - acc: 0.9209 - val_loss: 0.2803 - val_acc: 0.9218\n",
            "Epoch 149/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2836 - acc: 0.9208 - val_loss: 0.2802 - val_acc: 0.9216\n",
            "Epoch 150/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2835 - acc: 0.9210 - val_loss: 0.2800 - val_acc: 0.9225\n",
            "Epoch 151/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2833 - acc: 0.9210 - val_loss: 0.2799 - val_acc: 0.9226\n",
            "Epoch 152/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2831 - acc: 0.9211 - val_loss: 0.2798 - val_acc: 0.9222\n",
            "Epoch 153/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2829 - acc: 0.9207 - val_loss: 0.2797 - val_acc: 0.9224\n",
            "Epoch 154/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2827 - acc: 0.9209 - val_loss: 0.2796 - val_acc: 0.9222\n",
            "Epoch 155/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2826 - acc: 0.9208 - val_loss: 0.2795 - val_acc: 0.9225\n",
            "Epoch 156/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2824 - acc: 0.9210 - val_loss: 0.2794 - val_acc: 0.9224\n",
            "Epoch 157/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.2822 - acc: 0.9210 - val_loss: 0.2793 - val_acc: 0.9224\n",
            "Epoch 158/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2821 - acc: 0.9214 - val_loss: 0.2792 - val_acc: 0.9226\n",
            "Epoch 159/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2819 - acc: 0.9214 - val_loss: 0.2791 - val_acc: 0.9226\n",
            "Epoch 160/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2817 - acc: 0.9213 - val_loss: 0.2790 - val_acc: 0.9225\n",
            "Epoch 161/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2816 - acc: 0.9214 - val_loss: 0.2789 - val_acc: 0.9222\n",
            "Epoch 162/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2814 - acc: 0.9215 - val_loss: 0.2788 - val_acc: 0.9227\n",
            "Epoch 163/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2812 - acc: 0.9213 - val_loss: 0.2787 - val_acc: 0.9225\n",
            "Epoch 164/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2811 - acc: 0.9216 - val_loss: 0.2786 - val_acc: 0.9225\n",
            "Epoch 165/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2809 - acc: 0.9215 - val_loss: 0.2785 - val_acc: 0.9227\n",
            "Epoch 166/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2807 - acc: 0.9216 - val_loss: 0.2784 - val_acc: 0.9225\n",
            "Epoch 167/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2806 - acc: 0.9217 - val_loss: 0.2784 - val_acc: 0.9227\n",
            "Epoch 168/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2804 - acc: 0.9219 - val_loss: 0.2782 - val_acc: 0.9228\n",
            "Epoch 169/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2803 - acc: 0.9216 - val_loss: 0.2782 - val_acc: 0.9227\n",
            "Epoch 170/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2801 - acc: 0.9216 - val_loss: 0.2781 - val_acc: 0.9227\n",
            "Epoch 171/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2800 - acc: 0.9220 - val_loss: 0.2780 - val_acc: 0.9226\n",
            "Epoch 172/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2798 - acc: 0.9218 - val_loss: 0.2778 - val_acc: 0.9231\n",
            "Epoch 173/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2797 - acc: 0.9217 - val_loss: 0.2778 - val_acc: 0.9229\n",
            "Epoch 174/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2796 - acc: 0.9217 - val_loss: 0.2777 - val_acc: 0.9227\n",
            "Epoch 175/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2794 - acc: 0.9218 - val_loss: 0.2776 - val_acc: 0.9232\n",
            "Epoch 176/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2793 - acc: 0.9220 - val_loss: 0.2775 - val_acc: 0.9232\n",
            "Epoch 177/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2791 - acc: 0.9219 - val_loss: 0.2774 - val_acc: 0.9234\n",
            "Epoch 178/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2790 - acc: 0.9221 - val_loss: 0.2774 - val_acc: 0.9228\n",
            "Epoch 179/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2788 - acc: 0.9221 - val_loss: 0.2773 - val_acc: 0.9232\n",
            "Epoch 180/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2787 - acc: 0.9221 - val_loss: 0.2771 - val_acc: 0.9235\n",
            "Epoch 181/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2785 - acc: 0.9223 - val_loss: 0.2770 - val_acc: 0.9232\n",
            "Epoch 182/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.2784 - acc: 0.9220 - val_loss: 0.2769 - val_acc: 0.9231\n",
            "Epoch 183/200\n",
            "48000/48000 [==============================] - 1s 31us/step - loss: 0.2783 - acc: 0.9223 - val_loss: 0.2769 - val_acc: 0.9231\n",
            "Epoch 184/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2781 - acc: 0.9223 - val_loss: 0.2768 - val_acc: 0.9230\n",
            "Epoch 185/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2780 - acc: 0.9224 - val_loss: 0.2767 - val_acc: 0.9233\n",
            "Epoch 186/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2779 - acc: 0.9223 - val_loss: 0.2766 - val_acc: 0.9236\n",
            "Epoch 187/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2777 - acc: 0.9224 - val_loss: 0.2766 - val_acc: 0.9233\n",
            "Epoch 188/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2776 - acc: 0.9226 - val_loss: 0.2765 - val_acc: 0.9236\n",
            "Epoch 189/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2775 - acc: 0.9225 - val_loss: 0.2764 - val_acc: 0.9235\n",
            "Epoch 190/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2773 - acc: 0.9225 - val_loss: 0.2764 - val_acc: 0.9235\n",
            "Epoch 191/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2772 - acc: 0.9225 - val_loss: 0.2763 - val_acc: 0.9237\n",
            "Epoch 192/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2770 - acc: 0.9226 - val_loss: 0.2762 - val_acc: 0.9238\n",
            "Epoch 193/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2770 - acc: 0.9226 - val_loss: 0.2761 - val_acc: 0.9237\n",
            "Epoch 194/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2768 - acc: 0.9226 - val_loss: 0.2761 - val_acc: 0.9236\n",
            "Epoch 195/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2767 - acc: 0.9231 - val_loss: 0.2760 - val_acc: 0.9239\n",
            "Epoch 196/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2766 - acc: 0.9226 - val_loss: 0.2758 - val_acc: 0.9241\n",
            "Epoch 197/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2765 - acc: 0.9229 - val_loss: 0.2758 - val_acc: 0.9242\n",
            "Epoch 198/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2763 - acc: 0.9231 - val_loss: 0.2758 - val_acc: 0.9236\n",
            "Epoch 199/200\n",
            "48000/48000 [==============================] - 1s 30us/step - loss: 0.2762 - acc: 0.9229 - val_loss: 0.2757 - val_acc: 0.9241\n",
            "Epoch 200/200\n",
            "48000/48000 [==============================] - 1s 29us/step - loss: 0.2761 - acc: 0.9230 - val_loss: 0.2756 - val_acc: 0.9241\n",
            "10000/10000 [==============================] - 0s 45us/step\n",
            "\n",
            "Test score: 0.27738585557043555\n",
            "Test accuracy: 0.9227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KrFR80dT2Hbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1351
        },
        "outputId": "67d018ab-dcb3-40e0-e499-2ae71fd5484c"
      },
      "cell_type": "code",
      "source": [
        "# Version 2  - 히든 레이어 추가 \n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "np.random.seed(1671)  # for reproducibility\n",
        "\n",
        "# network and training\n",
        "NB_EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "\n",
        "# data: shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalize \n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# M_HIDDEN hidden layers\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 2s 52us/step - loss: 1.4829 - acc: 0.6231 - val_loss: 0.7584 - val_acc: 0.8286\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.6049 - acc: 0.8464 - val_loss: 0.4550 - val_acc: 0.8852\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.4398 - acc: 0.8801 - val_loss: 0.3710 - val_acc: 0.9019\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.3767 - acc: 0.8952 - val_loss: 0.3322 - val_acc: 0.9082\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.3415 - acc: 0.9025 - val_loss: 0.3055 - val_acc: 0.9147\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.3175 - acc: 0.9086 - val_loss: 0.2880 - val_acc: 0.9182\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.2989 - acc: 0.9137 - val_loss: 0.2727 - val_acc: 0.9224\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.2839 - acc: 0.9180 - val_loss: 0.2608 - val_acc: 0.9266\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.2714 - acc: 0.9217 - val_loss: 0.2505 - val_acc: 0.9298\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.2602 - acc: 0.9252 - val_loss: 0.2430 - val_acc: 0.9307\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.2501 - acc: 0.9285 - val_loss: 0.2341 - val_acc: 0.9335\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.2409 - acc: 0.9301 - val_loss: 0.2271 - val_acc: 0.9352\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.2325 - acc: 0.9333 - val_loss: 0.2227 - val_acc: 0.9365\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.2253 - acc: 0.9354 - val_loss: 0.2147 - val_acc: 0.9396\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.2181 - acc: 0.9375 - val_loss: 0.2082 - val_acc: 0.9410\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.2116 - acc: 0.9393 - val_loss: 0.2030 - val_acc: 0.9431\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.2055 - acc: 0.9414 - val_loss: 0.1981 - val_acc: 0.9444\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 2s 35us/step - loss: 0.1996 - acc: 0.9430 - val_loss: 0.1932 - val_acc: 0.9458\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.1941 - acc: 0.9432 - val_loss: 0.1894 - val_acc: 0.9468\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 2s 34us/step - loss: 0.1890 - acc: 0.9456 - val_loss: 0.1849 - val_acc: 0.9497\n",
            "10000/10000 [==============================] - 0s 46us/step\n",
            "\n",
            "Test score: 0.18600710261017084\n",
            "Test accuracy: 0.9463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hV-txTFo2J0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10367
        },
        "outputId": "160bcd56-442d-4962-a65e-7f9fb40d0475"
      },
      "cell_type": "code",
      "source": [
        "# Version 3 - 드롭아웃 추가 \n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1671)  # for reproducibility\n",
        "\n",
        "# network and training\n",
        "NB_EPOCH = 250\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "DROPOUT = 0.3\n",
        "\n",
        "# data: shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalize \n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# M_HIDDEN hidden layers\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 1.7404 - acc: 0.4539 - val_loss: 0.9293 - val_acc: 0.8124\n",
            "Epoch 2/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.9232 - acc: 0.7229 - val_loss: 0.5400 - val_acc: 0.8652\n",
            "Epoch 3/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.6935 - acc: 0.7881 - val_loss: 0.4298 - val_acc: 0.8883\n",
            "Epoch 4/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.5947 - acc: 0.8209 - val_loss: 0.3790 - val_acc: 0.8977\n",
            "Epoch 5/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.5347 - acc: 0.8393 - val_loss: 0.3456 - val_acc: 0.9039\n",
            "Epoch 6/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.4976 - acc: 0.8524 - val_loss: 0.3232 - val_acc: 0.9107\n",
            "Epoch 7/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.4616 - acc: 0.8628 - val_loss: 0.3048 - val_acc: 0.9129\n",
            "Epoch 8/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.4386 - acc: 0.8687 - val_loss: 0.2896 - val_acc: 0.9171\n",
            "Epoch 9/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.4181 - acc: 0.8761 - val_loss: 0.2776 - val_acc: 0.9198\n",
            "Epoch 10/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3990 - acc: 0.8838 - val_loss: 0.2656 - val_acc: 0.9233\n",
            "Epoch 11/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3819 - acc: 0.8876 - val_loss: 0.2552 - val_acc: 0.9257\n",
            "Epoch 12/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.3688 - acc: 0.8920 - val_loss: 0.2465 - val_acc: 0.9284\n",
            "Epoch 13/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3571 - acc: 0.8944 - val_loss: 0.2388 - val_acc: 0.9298\n",
            "Epoch 14/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3466 - acc: 0.8992 - val_loss: 0.2320 - val_acc: 0.9322\n",
            "Epoch 15/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3359 - acc: 0.9015 - val_loss: 0.2261 - val_acc: 0.9340\n",
            "Epoch 16/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3244 - acc: 0.9055 - val_loss: 0.2180 - val_acc: 0.9352\n",
            "Epoch 17/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3142 - acc: 0.9085 - val_loss: 0.2121 - val_acc: 0.9377\n",
            "Epoch 18/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3102 - acc: 0.9094 - val_loss: 0.2076 - val_acc: 0.9388\n",
            "Epoch 19/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.3019 - acc: 0.9118 - val_loss: 0.2018 - val_acc: 0.9409\n",
            "Epoch 20/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.2931 - acc: 0.9130 - val_loss: 0.1974 - val_acc: 0.9421\n",
            "Epoch 21/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2866 - acc: 0.9172 - val_loss: 0.1920 - val_acc: 0.9440\n",
            "Epoch 22/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2789 - acc: 0.9172 - val_loss: 0.1878 - val_acc: 0.9447\n",
            "Epoch 23/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2730 - acc: 0.9199 - val_loss: 0.1841 - val_acc: 0.9465\n",
            "Epoch 24/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2686 - acc: 0.9210 - val_loss: 0.1810 - val_acc: 0.9465\n",
            "Epoch 25/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2618 - acc: 0.9234 - val_loss: 0.1770 - val_acc: 0.9479\n",
            "Epoch 26/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2584 - acc: 0.9249 - val_loss: 0.1736 - val_acc: 0.9488\n",
            "Epoch 27/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2539 - acc: 0.9253 - val_loss: 0.1706 - val_acc: 0.9494\n",
            "Epoch 28/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2453 - acc: 0.9277 - val_loss: 0.1677 - val_acc: 0.9500\n",
            "Epoch 29/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2427 - acc: 0.9274 - val_loss: 0.1641 - val_acc: 0.9517\n",
            "Epoch 30/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2397 - acc: 0.9295 - val_loss: 0.1615 - val_acc: 0.9521\n",
            "Epoch 31/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2360 - acc: 0.9304 - val_loss: 0.1590 - val_acc: 0.9532\n",
            "Epoch 32/250\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2320 - acc: 0.9306 - val_loss: 0.1568 - val_acc: 0.9543\n",
            "Epoch 33/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2284 - acc: 0.9328 - val_loss: 0.1534 - val_acc: 0.9553\n",
            "Epoch 34/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2257 - acc: 0.9325 - val_loss: 0.1519 - val_acc: 0.9551\n",
            "Epoch 35/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2214 - acc: 0.9355 - val_loss: 0.1502 - val_acc: 0.9557\n",
            "Epoch 36/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2169 - acc: 0.9354 - val_loss: 0.1484 - val_acc: 0.9563\n",
            "Epoch 37/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.2124 - acc: 0.9376 - val_loss: 0.1459 - val_acc: 0.9571\n",
            "Epoch 38/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2122 - acc: 0.9372 - val_loss: 0.1432 - val_acc: 0.9579\n",
            "Epoch 39/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.2091 - acc: 0.9387 - val_loss: 0.1422 - val_acc: 0.9576\n",
            "Epoch 40/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.2042 - acc: 0.9393 - val_loss: 0.1410 - val_acc: 0.9580\n",
            "Epoch 41/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.2027 - acc: 0.9398 - val_loss: 0.1396 - val_acc: 0.9584\n",
            "Epoch 42/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1984 - acc: 0.9415 - val_loss: 0.1367 - val_acc: 0.9594\n",
            "Epoch 43/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.2003 - acc: 0.9410 - val_loss: 0.1349 - val_acc: 0.9607\n",
            "Epoch 44/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1953 - acc: 0.9423 - val_loss: 0.1337 - val_acc: 0.9607\n",
            "Epoch 45/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1920 - acc: 0.9432 - val_loss: 0.1331 - val_acc: 0.9601\n",
            "Epoch 46/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1901 - acc: 0.9444 - val_loss: 0.1316 - val_acc: 0.9616\n",
            "Epoch 47/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1876 - acc: 0.9449 - val_loss: 0.1299 - val_acc: 0.9611\n",
            "Epoch 48/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1867 - acc: 0.9442 - val_loss: 0.1300 - val_acc: 0.9616\n",
            "Epoch 49/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1865 - acc: 0.9453 - val_loss: 0.1282 - val_acc: 0.9614\n",
            "Epoch 50/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1803 - acc: 0.9463 - val_loss: 0.1266 - val_acc: 0.9623\n",
            "Epoch 51/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1822 - acc: 0.9466 - val_loss: 0.1254 - val_acc: 0.9636\n",
            "Epoch 52/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1794 - acc: 0.9460 - val_loss: 0.1244 - val_acc: 0.9634\n",
            "Epoch 53/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1752 - acc: 0.9480 - val_loss: 0.1233 - val_acc: 0.9635\n",
            "Epoch 54/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1738 - acc: 0.9478 - val_loss: 0.1220 - val_acc: 0.9637\n",
            "Epoch 55/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1735 - acc: 0.9492 - val_loss: 0.1208 - val_acc: 0.9647\n",
            "Epoch 56/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1719 - acc: 0.9487 - val_loss: 0.1207 - val_acc: 0.9637\n",
            "Epoch 57/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1692 - acc: 0.9502 - val_loss: 0.1188 - val_acc: 0.9651\n",
            "Epoch 58/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1663 - acc: 0.9506 - val_loss: 0.1187 - val_acc: 0.9650\n",
            "Epoch 59/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1682 - acc: 0.9500 - val_loss: 0.1172 - val_acc: 0.9654\n",
            "Epoch 60/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1647 - acc: 0.9514 - val_loss: 0.1165 - val_acc: 0.9653\n",
            "Epoch 61/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1614 - acc: 0.9522 - val_loss: 0.1156 - val_acc: 0.9659\n",
            "Epoch 62/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1592 - acc: 0.9527 - val_loss: 0.1149 - val_acc: 0.9657\n",
            "Epoch 63/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1587 - acc: 0.9533 - val_loss: 0.1142 - val_acc: 0.9655\n",
            "Epoch 64/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1564 - acc: 0.9531 - val_loss: 0.1125 - val_acc: 0.9667\n",
            "Epoch 65/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1560 - acc: 0.9540 - val_loss: 0.1128 - val_acc: 0.9668\n",
            "Epoch 66/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1572 - acc: 0.9536 - val_loss: 0.1119 - val_acc: 0.9662\n",
            "Epoch 67/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1553 - acc: 0.9547 - val_loss: 0.1105 - val_acc: 0.9668\n",
            "Epoch 68/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1525 - acc: 0.9544 - val_loss: 0.1102 - val_acc: 0.9673\n",
            "Epoch 69/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1523 - acc: 0.9552 - val_loss: 0.1088 - val_acc: 0.9677\n",
            "Epoch 70/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1502 - acc: 0.9552 - val_loss: 0.1085 - val_acc: 0.9678\n",
            "Epoch 71/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1478 - acc: 0.9566 - val_loss: 0.1082 - val_acc: 0.9679\n",
            "Epoch 72/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1450 - acc: 0.9568 - val_loss: 0.1072 - val_acc: 0.9684\n",
            "Epoch 73/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1462 - acc: 0.9569 - val_loss: 0.1068 - val_acc: 0.9678\n",
            "Epoch 74/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1439 - acc: 0.9583 - val_loss: 0.1067 - val_acc: 0.9683\n",
            "Epoch 75/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1447 - acc: 0.9567 - val_loss: 0.1058 - val_acc: 0.9682\n",
            "Epoch 76/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1413 - acc: 0.9580 - val_loss: 0.1059 - val_acc: 0.9683\n",
            "Epoch 77/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1420 - acc: 0.9581 - val_loss: 0.1055 - val_acc: 0.9680\n",
            "Epoch 78/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1398 - acc: 0.9587 - val_loss: 0.1044 - val_acc: 0.9691\n",
            "Epoch 79/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1415 - acc: 0.9572 - val_loss: 0.1041 - val_acc: 0.9687\n",
            "Epoch 80/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1392 - acc: 0.9595 - val_loss: 0.1033 - val_acc: 0.9689\n",
            "Epoch 81/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1370 - acc: 0.9593 - val_loss: 0.1035 - val_acc: 0.9689\n",
            "Epoch 82/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1365 - acc: 0.9579 - val_loss: 0.1031 - val_acc: 0.9687\n",
            "Epoch 83/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1344 - acc: 0.9597 - val_loss: 0.1019 - val_acc: 0.9693\n",
            "Epoch 84/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1337 - acc: 0.9600 - val_loss: 0.1013 - val_acc: 0.9692\n",
            "Epoch 85/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1337 - acc: 0.9604 - val_loss: 0.1014 - val_acc: 0.9695\n",
            "Epoch 86/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1345 - acc: 0.9602 - val_loss: 0.1005 - val_acc: 0.9699\n",
            "Epoch 87/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1304 - acc: 0.9607 - val_loss: 0.1003 - val_acc: 0.9703\n",
            "Epoch 88/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1321 - acc: 0.9595 - val_loss: 0.0999 - val_acc: 0.9698\n",
            "Epoch 89/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1304 - acc: 0.9608 - val_loss: 0.0990 - val_acc: 0.9705\n",
            "Epoch 90/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1321 - acc: 0.9604 - val_loss: 0.0986 - val_acc: 0.9704\n",
            "Epoch 91/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1285 - acc: 0.9622 - val_loss: 0.0981 - val_acc: 0.9707\n",
            "Epoch 92/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1318 - acc: 0.9602 - val_loss: 0.0985 - val_acc: 0.9716\n",
            "Epoch 93/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1285 - acc: 0.9615 - val_loss: 0.0976 - val_acc: 0.9711\n",
            "Epoch 94/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1249 - acc: 0.9622 - val_loss: 0.0974 - val_acc: 0.9710\n",
            "Epoch 95/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1265 - acc: 0.9627 - val_loss: 0.0973 - val_acc: 0.9715\n",
            "Epoch 96/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1239 - acc: 0.9625 - val_loss: 0.0969 - val_acc: 0.9716\n",
            "Epoch 97/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1241 - acc: 0.9621 - val_loss: 0.0959 - val_acc: 0.9712\n",
            "Epoch 98/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1235 - acc: 0.9632 - val_loss: 0.0964 - val_acc: 0.9717\n",
            "Epoch 99/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.1216 - acc: 0.9641 - val_loss: 0.0956 - val_acc: 0.9718\n",
            "Epoch 100/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1211 - acc: 0.9636 - val_loss: 0.0956 - val_acc: 0.9719\n",
            "Epoch 101/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1227 - acc: 0.9631 - val_loss: 0.0960 - val_acc: 0.9723\n",
            "Epoch 102/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1214 - acc: 0.9640 - val_loss: 0.0946 - val_acc: 0.9722\n",
            "Epoch 103/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1192 - acc: 0.9647 - val_loss: 0.0949 - val_acc: 0.9720\n",
            "Epoch 104/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1177 - acc: 0.9646 - val_loss: 0.0941 - val_acc: 0.9722\n",
            "Epoch 105/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1163 - acc: 0.9655 - val_loss: 0.0942 - val_acc: 0.9728\n",
            "Epoch 106/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1169 - acc: 0.9650 - val_loss: 0.0939 - val_acc: 0.9725\n",
            "Epoch 107/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1169 - acc: 0.9646 - val_loss: 0.0940 - val_acc: 0.9731\n",
            "Epoch 108/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1138 - acc: 0.9664 - val_loss: 0.0932 - val_acc: 0.9724\n",
            "Epoch 109/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1146 - acc: 0.9658 - val_loss: 0.0933 - val_acc: 0.9732\n",
            "Epoch 110/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1140 - acc: 0.9661 - val_loss: 0.0927 - val_acc: 0.9727\n",
            "Epoch 111/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1146 - acc: 0.9659 - val_loss: 0.0926 - val_acc: 0.9722\n",
            "Epoch 112/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1117 - acc: 0.9660 - val_loss: 0.0917 - val_acc: 0.9737\n",
            "Epoch 113/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1126 - acc: 0.9659 - val_loss: 0.0920 - val_acc: 0.9732\n",
            "Epoch 114/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1144 - acc: 0.9657 - val_loss: 0.0914 - val_acc: 0.9737\n",
            "Epoch 115/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1113 - acc: 0.9663 - val_loss: 0.0913 - val_acc: 0.9742\n",
            "Epoch 116/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1087 - acc: 0.9674 - val_loss: 0.0911 - val_acc: 0.9737\n",
            "Epoch 117/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1115 - acc: 0.9664 - val_loss: 0.0912 - val_acc: 0.9737\n",
            "Epoch 118/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1086 - acc: 0.9670 - val_loss: 0.0907 - val_acc: 0.9739\n",
            "Epoch 119/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1117 - acc: 0.9662 - val_loss: 0.0910 - val_acc: 0.9741\n",
            "Epoch 120/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1070 - acc: 0.9676 - val_loss: 0.0901 - val_acc: 0.9742\n",
            "Epoch 121/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1083 - acc: 0.9669 - val_loss: 0.0904 - val_acc: 0.9744\n",
            "Epoch 122/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1074 - acc: 0.9673 - val_loss: 0.0895 - val_acc: 0.9747\n",
            "Epoch 123/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1042 - acc: 0.9679 - val_loss: 0.0891 - val_acc: 0.9747\n",
            "Epoch 124/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1046 - acc: 0.9683 - val_loss: 0.0894 - val_acc: 0.9745\n",
            "Epoch 125/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1043 - acc: 0.9691 - val_loss: 0.0891 - val_acc: 0.9742\n",
            "Epoch 126/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1035 - acc: 0.9684 - val_loss: 0.0888 - val_acc: 0.9745\n",
            "Epoch 127/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1033 - acc: 0.9684 - val_loss: 0.0889 - val_acc: 0.9747\n",
            "Epoch 128/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1042 - acc: 0.9686 - val_loss: 0.0883 - val_acc: 0.9749\n",
            "Epoch 129/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1050 - acc: 0.9677 - val_loss: 0.0883 - val_acc: 0.9754\n",
            "Epoch 130/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.1039 - acc: 0.9689 - val_loss: 0.0883 - val_acc: 0.9753\n",
            "Epoch 131/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1025 - acc: 0.9689 - val_loss: 0.0875 - val_acc: 0.9752\n",
            "Epoch 132/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0998 - acc: 0.9703 - val_loss: 0.0879 - val_acc: 0.9751\n",
            "Epoch 133/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1009 - acc: 0.9687 - val_loss: 0.0876 - val_acc: 0.9752\n",
            "Epoch 134/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0989 - acc: 0.9688 - val_loss: 0.0876 - val_acc: 0.9748\n",
            "Epoch 135/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1007 - acc: 0.9692 - val_loss: 0.0879 - val_acc: 0.9748\n",
            "Epoch 136/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1000 - acc: 0.9702 - val_loss: 0.0875 - val_acc: 0.9752\n",
            "Epoch 137/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0996 - acc: 0.9694 - val_loss: 0.0877 - val_acc: 0.9755\n",
            "Epoch 138/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.1003 - acc: 0.9692 - val_loss: 0.0874 - val_acc: 0.9755\n",
            "Epoch 139/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0975 - acc: 0.9705 - val_loss: 0.0872 - val_acc: 0.9752\n",
            "Epoch 140/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0964 - acc: 0.9707 - val_loss: 0.0868 - val_acc: 0.9758\n",
            "Epoch 141/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0971 - acc: 0.9697 - val_loss: 0.0867 - val_acc: 0.9760\n",
            "Epoch 142/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0952 - acc: 0.9709 - val_loss: 0.0864 - val_acc: 0.9761\n",
            "Epoch 143/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0968 - acc: 0.9701 - val_loss: 0.0867 - val_acc: 0.9759\n",
            "Epoch 144/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0945 - acc: 0.9713 - val_loss: 0.0864 - val_acc: 0.9759\n",
            "Epoch 145/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0961 - acc: 0.9709 - val_loss: 0.0858 - val_acc: 0.9760\n",
            "Epoch 146/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0939 - acc: 0.9720 - val_loss: 0.0863 - val_acc: 0.9753\n",
            "Epoch 147/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0935 - acc: 0.9714 - val_loss: 0.0865 - val_acc: 0.9761\n",
            "Epoch 148/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0948 - acc: 0.9707 - val_loss: 0.0860 - val_acc: 0.9761\n",
            "Epoch 149/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0925 - acc: 0.9720 - val_loss: 0.0855 - val_acc: 0.9757\n",
            "Epoch 150/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0917 - acc: 0.9722 - val_loss: 0.0862 - val_acc: 0.9760\n",
            "Epoch 151/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0941 - acc: 0.9719 - val_loss: 0.0856 - val_acc: 0.9761\n",
            "Epoch 152/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0923 - acc: 0.9723 - val_loss: 0.0852 - val_acc: 0.9765\n",
            "Epoch 153/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0892 - acc: 0.9728 - val_loss: 0.0851 - val_acc: 0.9758\n",
            "Epoch 154/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0916 - acc: 0.9723 - val_loss: 0.0853 - val_acc: 0.9761\n",
            "Epoch 155/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0908 - acc: 0.9725 - val_loss: 0.0849 - val_acc: 0.9761\n",
            "Epoch 156/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0911 - acc: 0.9726 - val_loss: 0.0848 - val_acc: 0.9757\n",
            "Epoch 157/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0900 - acc: 0.9732 - val_loss: 0.0849 - val_acc: 0.9760\n",
            "Epoch 158/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0885 - acc: 0.9733 - val_loss: 0.0853 - val_acc: 0.9762\n",
            "Epoch 159/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0878 - acc: 0.9726 - val_loss: 0.0845 - val_acc: 0.9767\n",
            "Epoch 160/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0893 - acc: 0.9730 - val_loss: 0.0848 - val_acc: 0.9762\n",
            "Epoch 161/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0887 - acc: 0.9728 - val_loss: 0.0841 - val_acc: 0.9766\n",
            "Epoch 162/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0884 - acc: 0.9735 - val_loss: 0.0842 - val_acc: 0.9765\n",
            "Epoch 163/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0869 - acc: 0.9733 - val_loss: 0.0846 - val_acc: 0.9764\n",
            "Epoch 164/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0878 - acc: 0.9730 - val_loss: 0.0840 - val_acc: 0.9768\n",
            "Epoch 165/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0859 - acc: 0.9735 - val_loss: 0.0838 - val_acc: 0.9763\n",
            "Epoch 166/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0862 - acc: 0.9731 - val_loss: 0.0847 - val_acc: 0.9763\n",
            "Epoch 167/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0857 - acc: 0.9736 - val_loss: 0.0846 - val_acc: 0.9760\n",
            "Epoch 168/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0837 - acc: 0.9749 - val_loss: 0.0842 - val_acc: 0.9763\n",
            "Epoch 169/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0852 - acc: 0.9741 - val_loss: 0.0838 - val_acc: 0.9760\n",
            "Epoch 170/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0871 - acc: 0.9735 - val_loss: 0.0833 - val_acc: 0.9763\n",
            "Epoch 171/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0854 - acc: 0.9738 - val_loss: 0.0831 - val_acc: 0.9767\n",
            "Epoch 172/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0845 - acc: 0.9737 - val_loss: 0.0832 - val_acc: 0.9761\n",
            "Epoch 173/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0858 - acc: 0.9739 - val_loss: 0.0839 - val_acc: 0.9765\n",
            "Epoch 174/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0826 - acc: 0.9749 - val_loss: 0.0832 - val_acc: 0.9762\n",
            "Epoch 175/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0857 - acc: 0.9733 - val_loss: 0.0836 - val_acc: 0.9764\n",
            "Epoch 176/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0806 - acc: 0.9752 - val_loss: 0.0837 - val_acc: 0.9767\n",
            "Epoch 177/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0823 - acc: 0.9751 - val_loss: 0.0828 - val_acc: 0.9770\n",
            "Epoch 178/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0824 - acc: 0.9747 - val_loss: 0.0826 - val_acc: 0.9772\n",
            "Epoch 179/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0812 - acc: 0.9751 - val_loss: 0.0821 - val_acc: 0.9763\n",
            "Epoch 180/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0834 - acc: 0.9741 - val_loss: 0.0829 - val_acc: 0.9770\n",
            "Epoch 181/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0811 - acc: 0.9748 - val_loss: 0.0818 - val_acc: 0.9767\n",
            "Epoch 182/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0784 - acc: 0.9757 - val_loss: 0.0826 - val_acc: 0.9771\n",
            "Epoch 183/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0803 - acc: 0.9759 - val_loss: 0.0823 - val_acc: 0.9767\n",
            "Epoch 184/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0808 - acc: 0.9751 - val_loss: 0.0817 - val_acc: 0.9767\n",
            "Epoch 185/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0791 - acc: 0.9754 - val_loss: 0.0821 - val_acc: 0.9765\n",
            "Epoch 186/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0806 - acc: 0.9756 - val_loss: 0.0824 - val_acc: 0.9766\n",
            "Epoch 187/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0785 - acc: 0.9757 - val_loss: 0.0820 - val_acc: 0.9767\n",
            "Epoch 188/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0795 - acc: 0.9753 - val_loss: 0.0812 - val_acc: 0.9767\n",
            "Epoch 189/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0774 - acc: 0.9759 - val_loss: 0.0820 - val_acc: 0.9769\n",
            "Epoch 190/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0775 - acc: 0.9760 - val_loss: 0.0820 - val_acc: 0.9765\n",
            "Epoch 191/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0779 - acc: 0.9769 - val_loss: 0.0821 - val_acc: 0.9764\n",
            "Epoch 192/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0796 - acc: 0.9757 - val_loss: 0.0820 - val_acc: 0.9772\n",
            "Epoch 193/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0775 - acc: 0.9763 - val_loss: 0.0817 - val_acc: 0.9769\n",
            "Epoch 194/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0779 - acc: 0.9761 - val_loss: 0.0817 - val_acc: 0.9767\n",
            "Epoch 195/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0767 - acc: 0.9764 - val_loss: 0.0819 - val_acc: 0.9766\n",
            "Epoch 196/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0741 - acc: 0.9771 - val_loss: 0.0817 - val_acc: 0.9763\n",
            "Epoch 197/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0769 - acc: 0.9759 - val_loss: 0.0815 - val_acc: 0.9768\n",
            "Epoch 198/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0749 - acc: 0.9769 - val_loss: 0.0813 - val_acc: 0.9768\n",
            "Epoch 199/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0750 - acc: 0.9770 - val_loss: 0.0810 - val_acc: 0.9769\n",
            "Epoch 200/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0742 - acc: 0.9768 - val_loss: 0.0808 - val_acc: 0.9763\n",
            "Epoch 201/250\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.0745 - acc: 0.9764 - val_loss: 0.0814 - val_acc: 0.9771\n",
            "Epoch 202/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0781 - acc: 0.9762 - val_loss: 0.0810 - val_acc: 0.9773\n",
            "Epoch 203/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0748 - acc: 0.9771 - val_loss: 0.0809 - val_acc: 0.9769\n",
            "Epoch 204/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0719 - acc: 0.9773 - val_loss: 0.0810 - val_acc: 0.9772\n",
            "Epoch 205/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0753 - acc: 0.9768 - val_loss: 0.0813 - val_acc: 0.9769\n",
            "Epoch 206/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0730 - acc: 0.9772 - val_loss: 0.0812 - val_acc: 0.9772\n",
            "Epoch 207/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0724 - acc: 0.9775 - val_loss: 0.0811 - val_acc: 0.9763\n",
            "Epoch 208/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0725 - acc: 0.9771 - val_loss: 0.0813 - val_acc: 0.9771\n",
            "Epoch 209/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0731 - acc: 0.9775 - val_loss: 0.0813 - val_acc: 0.9768\n",
            "Epoch 210/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0710 - acc: 0.9779 - val_loss: 0.0815 - val_acc: 0.9770\n",
            "Epoch 211/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0733 - acc: 0.9767 - val_loss: 0.0819 - val_acc: 0.9770\n",
            "Epoch 212/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0738 - acc: 0.9772 - val_loss: 0.0814 - val_acc: 0.9767\n",
            "Epoch 213/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0724 - acc: 0.9779 - val_loss: 0.0808 - val_acc: 0.9777\n",
            "Epoch 214/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0721 - acc: 0.9779 - val_loss: 0.0810 - val_acc: 0.9776\n",
            "Epoch 215/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0705 - acc: 0.9785 - val_loss: 0.0808 - val_acc: 0.9773\n",
            "Epoch 216/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0707 - acc: 0.9777 - val_loss: 0.0808 - val_acc: 0.9770\n",
            "Epoch 217/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0707 - acc: 0.9784 - val_loss: 0.0806 - val_acc: 0.9775\n",
            "Epoch 218/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0686 - acc: 0.9786 - val_loss: 0.0809 - val_acc: 0.9772\n",
            "Epoch 219/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0706 - acc: 0.9780 - val_loss: 0.0802 - val_acc: 0.9770\n",
            "Epoch 220/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0688 - acc: 0.9789 - val_loss: 0.0802 - val_acc: 0.9772\n",
            "Epoch 221/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0704 - acc: 0.9779 - val_loss: 0.0811 - val_acc: 0.9769\n",
            "Epoch 222/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0687 - acc: 0.9786 - val_loss: 0.0807 - val_acc: 0.9770\n",
            "Epoch 223/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0706 - acc: 0.9774 - val_loss: 0.0806 - val_acc: 0.9772\n",
            "Epoch 224/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0698 - acc: 0.9791 - val_loss: 0.0803 - val_acc: 0.9772\n",
            "Epoch 225/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0673 - acc: 0.9790 - val_loss: 0.0805 - val_acc: 0.9777\n",
            "Epoch 226/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0683 - acc: 0.9788 - val_loss: 0.0804 - val_acc: 0.9772\n",
            "Epoch 227/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0667 - acc: 0.9791 - val_loss: 0.0806 - val_acc: 0.9772\n",
            "Epoch 228/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0693 - acc: 0.9788 - val_loss: 0.0806 - val_acc: 0.9770\n",
            "Epoch 229/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0688 - acc: 0.9784 - val_loss: 0.0805 - val_acc: 0.9770\n",
            "Epoch 230/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0684 - acc: 0.9788 - val_loss: 0.0801 - val_acc: 0.9768\n",
            "Epoch 231/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0670 - acc: 0.9793 - val_loss: 0.0798 - val_acc: 0.9777\n",
            "Epoch 232/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0681 - acc: 0.9787 - val_loss: 0.0800 - val_acc: 0.9773\n",
            "Epoch 233/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0647 - acc: 0.9795 - val_loss: 0.0805 - val_acc: 0.9780\n",
            "Epoch 234/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0678 - acc: 0.9782 - val_loss: 0.0802 - val_acc: 0.9777\n",
            "Epoch 235/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0664 - acc: 0.9794 - val_loss: 0.0794 - val_acc: 0.9773\n",
            "Epoch 236/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0686 - acc: 0.9784 - val_loss: 0.0794 - val_acc: 0.9773\n",
            "Epoch 237/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0650 - acc: 0.9796 - val_loss: 0.0800 - val_acc: 0.9773\n",
            "Epoch 238/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0664 - acc: 0.9794 - val_loss: 0.0804 - val_acc: 0.9776\n",
            "Epoch 239/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0668 - acc: 0.9793 - val_loss: 0.0806 - val_acc: 0.9778\n",
            "Epoch 240/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0687 - acc: 0.9787 - val_loss: 0.0803 - val_acc: 0.9777\n",
            "Epoch 241/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0648 - acc: 0.9798 - val_loss: 0.0806 - val_acc: 0.9773\n",
            "Epoch 242/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0656 - acc: 0.9789 - val_loss: 0.0797 - val_acc: 0.9777\n",
            "Epoch 243/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0658 - acc: 0.9792 - val_loss: 0.0795 - val_acc: 0.9779\n",
            "Epoch 244/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0654 - acc: 0.9797 - val_loss: 0.0797 - val_acc: 0.9777\n",
            "Epoch 245/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0634 - acc: 0.9803 - val_loss: 0.0799 - val_acc: 0.9776\n",
            "Epoch 246/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0628 - acc: 0.9802 - val_loss: 0.0809 - val_acc: 0.9772\n",
            "Epoch 247/250\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.0621 - acc: 0.9802 - val_loss: 0.0801 - val_acc: 0.9776\n",
            "Epoch 248/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0632 - acc: 0.9803 - val_loss: 0.0801 - val_acc: 0.9770\n",
            "Epoch 249/250\n",
            "48000/48000 [==============================] - 2s 36us/step - loss: 0.0635 - acc: 0.9799 - val_loss: 0.0804 - val_acc: 0.9777\n",
            "Epoch 250/250\n",
            "48000/48000 [==============================] - 2s 37us/step - loss: 0.0616 - acc: 0.9809 - val_loss: 0.0801 - val_acc: 0.9775\n",
            "10000/10000 [==============================] - 0s 49us/step\n",
            "\n",
            "Test score: 0.07748570286288159\n",
            "Test accuracy: 0.9779\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNFGDOoobYrMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Li1eYsjd5EjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2013
        },
        "outputId": "8d53aee4-9ae0-4ed8-e535-2c48ab856fae"
      },
      "cell_type": "code",
      "source": [
        "# version 4 - 옵티마이저 변경 \n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1671)  # for reproducibility\n",
        "\n",
        "# network and training\n",
        "NB_EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "OPTIMIZER = RMSprop() # optimizer, explainedin this chapter\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
        "DROPOUT = 0.3\n",
        "\n",
        "# data: shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalize \n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "# M_HIDDEN hidden layers\n",
        "# 10 outputs\n",
        "# final stage is softmax\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
        "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.4776 - acc: 0.8573 - val_loss: 0.1849 - val_acc: 0.9453\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.2260 - acc: 0.9332 - val_loss: 0.1397 - val_acc: 0.9582\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1743 - acc: 0.9478 - val_loss: 0.1205 - val_acc: 0.9643\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1513 - acc: 0.9547 - val_loss: 0.1160 - val_acc: 0.9665\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1349 - acc: 0.9597 - val_loss: 0.1031 - val_acc: 0.9708\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1230 - acc: 0.9627 - val_loss: 0.0971 - val_acc: 0.9716\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.1129 - acc: 0.9657 - val_loss: 0.1009 - val_acc: 0.9717\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.1059 - acc: 0.9691 - val_loss: 0.0961 - val_acc: 0.9737\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0972 - acc: 0.9708 - val_loss: 0.0973 - val_acc: 0.9746\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0943 - acc: 0.9712 - val_loss: 0.0929 - val_acc: 0.9751\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0885 - acc: 0.9726 - val_loss: 0.0923 - val_acc: 0.9756\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0862 - acc: 0.9747 - val_loss: 0.0916 - val_acc: 0.9759\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0843 - acc: 0.9748 - val_loss: 0.0919 - val_acc: 0.9761\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0809 - acc: 0.9764 - val_loss: 0.0987 - val_acc: 0.9761\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0815 - acc: 0.9756 - val_loss: 0.0940 - val_acc: 0.9775\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.0777 - acc: 0.9766 - val_loss: 0.0960 - val_acc: 0.9774\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0744 - acc: 0.9786 - val_loss: 0.1033 - val_acc: 0.9753\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0758 - acc: 0.9781 - val_loss: 0.0998 - val_acc: 0.9780\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.0726 - acc: 0.9789 - val_loss: 0.1096 - val_acc: 0.9758\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.0719 - acc: 0.9794 - val_loss: 0.1032 - val_acc: 0.9775\n",
            "10000/10000 [==============================] - 0s 49us/step\n",
            "\n",
            "Test score: 0.09722156832165565\n",
            "Test accuracy: 0.9789\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8VOW9P/DPmTWZLckkE0IWQgib\nJEVFRBBxwQAi2mqtGO61VZCl1bq017Ya7q9qqbjcWvVlrZe61aug0RKVagVFcSs0VJBV1oQsJJDM\nTCYzmX055/fHJAMBEgJkMks+79crr5kzZ5bvE5bPnOc8z3MESZIkEBERUcKTxboAIiIi6h8MdSIi\noiTBUCciIkoSDHUiIqIkwVAnIiJKEgx1IiKiJMFQJxoEli5diueee67X51RVVeH2228fmIKIKCoY\n6kREREmCoU4UZw4fPozLLrsML774ImbNmoVZs2Zh27ZtWLx4MaZNm4YHH3ww8tyPPvoI1113Ha65\n5hr85Cc/QUNDAwDAZrNhwYIFmD59OhYvXoyOjo7Iaw4ePIhbb70Vs2bNwvXXX4+dO3eetqbnn38e\ns2bNQllZGZYsWQKHwwEA8Hq9+PWvf43p06dj9uzZeP/993t9/IEHHsCf//znyPsevz19+nT86U9/\nwqxZs9Dc3Iza2lrMmzcPs2fPxowZM/DBBx9EXvfll19izpw5mDVrFpYsWYL29nbcc889ePnllyPP\n2b9/PyZPnoxgMHjGfwZEiYqhThSHbDYbTCYT1q1bhzFjxuAXv/gFHn/8caxZswYffPABGhoa0Nzc\njP/3//4fnn/+eaxduxZXXnklfvvb3wIAXnzxRWRkZOCzzz7Db3/7W3z99dcAAFEUcdddd+EHP/gB\n1q1bh4cffhh33nlnr8G3a9curFy5EqtXr8bHH38Mv9+PN954AwDwyiuvIBAI4LPPPsOrr76KZcuW\noaWlpcfHT6elpQXr1q1Dbm4unnzySVx11VX46KOPsHz5cixduhSBQAButxu/+tWv8PTTT2PdunUY\nNmwYnn32WVx33XXdgv+TTz7BzJkzoVAozuWPgiih8G87URwKBoO45pprAACjR48GABiNRgCAyWRC\na2srDh06hEsuuQSFhYUAgJtvvhn/8z//g2AwiG+++QaLFy8GAOTn52PSpEkAgNraWlitVvzoRz8C\nAFx00UUwGo349ttve6yltLQUn3/+OVQqFQDgwgsvRGNjI4DwEfPChQsBADk5Ofjiiy+g1Wp7fPx0\nrrzyysj9P//5z+haxfqiiy6Cz+eD2WxGbW0tcnJyIr+XX/3qVwAASZLw4IMPora2FiNGjMD69evx\nm9/85rSfSZRMGOpEcUgulyMlJQUAIJPJoNFouu0LhUKw2WwwGAyRx/V6PSRJgs1mg91uh16vj+zr\nep7D4YDX68Xs2bMj+5xOJ9rb23usxePx4LHHHkN1dTUAwG63R8LXZrN1+5yu4O7p8dNJS0uL3P/q\nq6/wwgsvwGazQRAESJIEURRPanfXlw0AkW76H/3oRzCbzZEvM0SDBUOdKEFlZmZ2O8K22+2QyWTI\nyMiAwWDodh69ra0NBQUFyM7Ohlarxdq1a096v6qqqlN+zmuvvYa6ujpUVVVBq9Xi6aefjnSlZ2Rk\nwGazRZ579OhRpKWl9fi4TCaDKIrdaj6VQCCA++67D8888wyuuOIK+P1+jB8//pSf6fF4YLfbkZOT\ngzlz5uCxxx6DXq/HrFmzIJPxDCMNLvwbT5Sgpk6dim+++SbSFf7WW29h6tSpUCgUuOCCC7B+/XoA\nQENDA7Zs2QIAyMvLQ05OTiTU29ra8Mtf/hJut7vHz7FarRgxYgS0Wi2amprwxRdfRJ4/ffp0vPfe\ne5AkCWazGTfccANsNluPj5tMJuzduxcA0NjYiK1bt57yMz0eD9xuN0pLSwGEv1golUq43W5cdNFF\nMJvN2LFjB4BwN/3zzz8PALj00kvR3t6O119/vVtvBNFgwSN1ogSVk5OD3//+97jzzjsRCASQn5+P\nZcuWAQCWLFmCX/ziF5g+fTqKi4sxc+ZMAIAgCPjjH/+Ihx9+GM888wxkMhnmz5/frXv/ROXl5bjn\nnnswa9YsjBkzBg888ADuvvtu/PWvf8Xtt9+O+vp6XHXVVUhJScFvfvMb5Obm9vj43Llz8fOf/xwz\nZ87EuHHjMGvWrFN+psFgwMKFC3HDDTcgMzMTP/vZz1BWVoaf/vSn+OCDD/Dcc89FzqUXFhbi8ccf\nBxA+NXHNNdfg008/xUUXXdSfv26ihCDweupElExefPFF2Gw2/PrXv451KUQDjt3vRJQ02tra8Pbb\nb2PevHmxLoUoJhjqRJQU3nrrLdx0001YtGgRCgoKYl0OUUyw+52IiChJ8EidiIgoSTDUiYiIkkTC\nT2kzmztO/6QzkJGhgc3W85zdRJWM7WKbEkcytottShzJ1i6TSd/jPh6pn0ChkMe6hKhIxnaxTYkj\nGdvFNiWOZG3XqTDUiYiIkgRDnYiIKEkw1ImIiJIEQ52IiChJMNSJiIiSBEOdiIgoSUR1nvry5cux\nfft2CIKAiooKjB8/PrJv/fr1eOGFF6BSqTBnzhzceuutcLlc+M1vfgO73Y5AIIC77roL06ZNi2aJ\nRERESSNqR+qbN29GfX09Kisr8eijj+LRRx+N7BNFEcuWLcOLL76IlStXYsOGDTh69CjeffddFBUV\n4fXXX8ezzz7b7TWJ5vPPP+3T85599ik0NzdFuRoiIhoMohbqmzZtQllZGQCguLgYdrsdTqcTAGCz\n2WAwGGA0GiGTyTB58mRs3LgRGRkZaG9vBwA4HA5kZGREq7yoOnKkGevXr+vTc++997+Qm5sX5YqI\niGgwiFr3u8ViQUlJSWTbaDTCbDZDp9PBaDTC5XKhrq4OeXl5qK6uxqRJk7B48WJUVVVhxowZcDgc\nWLFiRbTKi6o//vEJ7NmzG9OmXYyZM2fjyJFmPPPMn/HYY7+D2dwKj8eDBQsWY+rUafj5zxfjl7/8\nNTZs+BQulxMNDfVoajqMe+75L0yZMjXWTSEiogQyYGu/H3+FV0EQ8Pjjj6OiogJ6vR75+fkAgPff\nfx+5ubl4+eWXsXfvXlRUVKCqqqrX983I0PS6BOArf9+Nf27v3+7tqefnYcH1JT3u/9nPlmDlypUY\nNWoUamtr8c47lbBarbj66itx4403orGxEffeey9uuOFaqFQKZGRoodWq0dzcgNdeexVffvkl3nrr\nLXz/+9f0a929rRecqNimxJGM7WKbEke02hUKifD4gnB7g3D7gnB7A3B7g5HHPL4Axo80YUReWlQ+\n/0RRC/Xs7GxYLJbIdmtrK0wmU2R70qRJWLVqFQDgqaeeQl5eHjZv3ozLLrsMADB27Fi0trYiFApB\nLu85tE+3SL/H7Uco1PdLxsvlwmmf73H7e72QTHu7Gz5fAC6XDyNGjIbZ3IFgUIbNm7dg5cpVEAQZ\nrNY2mM0d8PuDsNlccLl8GDOmBGZzB9RqPdra2vv1YjUmk77fL34Ta2xT4kjGdrFNiaOndkmSBK8/\nhA63Hw53AE53AB5fEB5/OJS9/lB42xeC9/jH/CF4O5/nD4in/fzxxZm47+bz+7U9PYlaqE+dOhXP\nPfccysvLsXv3bmRnZ0On00X2L1y4EE888QRSU1OxYcMGzJ8/Hy0tLdi+fTtmzZqFpqYmaLXaXgO9\nL+ZOH4m500f2+fn9/ZdaqVQCAD75ZC0cDgeef/4lOBwOLFz445Oee3xbj+/ZICJKJG5vEIeOOlDb\nZEfd0Q4EQiI0agVSj/sJb8uPu3/8jxxy2dkN+fIHQnC4/ehwB8Jh7QpAFI7iqNkJh9t/0r5g6PSh\nfDyVQoYUtQKpKjnS9WqkqsJtSFEpkKKWI1UVrj/luNuR+QNzlA5EMdQnTJiAkpISlJeXQxAEPPTQ\nQ6iqqoJer8eMGTMwd+5cLFiwAIIgYPHixTAajbjllltQUVGBW2+9FcFgEA8//HC0yosqmUyGUCjU\n7bH29nYMHZoLmUyGL774DIFAIEbVERH1n5Ao4nCrC7VHHKhttqO22YGjVjfO9bBErZSfMvRT1HKI\n6nb4BTdkngz43IpwWLvCYe0LhE773iqFDHqNCgXZWug1Kug1Shg0Kug0yshndYVyaldYqxVIUZ39\nl42BEtVz6vfff3+37bFjx0buz5w5EzNnzuy2X6vV4tlnn41mSQOisLAI+/btxdChuUhPTwcAXHnl\ndDzwwC/x3Xe7MGfO95GdnY1XX30xxpUSUaIJiEFYPVZ0+J0QBBlkggABAoTOW5kgO3k7cl+AgM7X\nnOL5+oCy18+WJAltDl+3AK8/2gF/8NjRrlolx5hh6RiRm4YRuQYUDTVAo1bA7Qt2dmV3nm+O3A+d\ntO/4/R3uAFodDkg6C+TpZshTLBDgAyQAKYAoaSCFjFDLspCpHYJ0tRFpGlW3sM7PTYMYCMKgUcGg\nUUGtGphLsQbFIFrdFqSr06BRpg7IZwpSgvfz9vf5n8F2TimRsU2JIxnbFc02iZKINm87Wt1mtHos\naHVbwvfdFrR5bZDO+Ti4Z1mpmRiRVogRaYXITc2H156KuqNO1DY7UNvsgN3ljzxXEIC8LC1G5Boi\nIZ6bqYVMJpxTDZIkocl5BLute7Hbug+HHPUQpfAXB41Cg0JNMQyKNFgCR9HkboQ35Iu8Vq/UoTh9\nOIrThqM4vQj5ulzkDEmP+t8/h78DTc4jaHIeweGOI2hyNuOouxWiJOJ7WePw0/G399tnxeScOhER\n9UySJDj8zs7gDge22W1Bi8cCi9uCoHRyN7JepcOItOEYosmCQRX+j12EBEmSIEKEJHXdD99KkCBJ\nIsTI/fCtKImRbbHzOYFgCF7RjwbHYWz2bMXmo1vDdYbkEJ3pEN3p0OhMOD+vEKNyszBiqAHDh+qR\nouqfGPEEPdjbdhDfdQa53e8AAAgQMNxQgHGZY1CSORYF+jzIhGNd4KIkotl5FDX2OtS0H8LB9kPY\nZt6FbeZdAACVTInRWSNQoClAcfpwFBmGIUWRctZ1hsQQjrpbw+HtbEaz8ygOO5vR4Xd2e55KpsQw\nfT7ydEMxeejEs/68M8VQJ6JBSZREiJKIkCRClEIIiSJE9H3QlNIbDuUTub1BtLS50WIL/7S2eRCU\nuyFLdUNSORGQd8ADO5xiOwKS/6TXp8hTkKfLhUmTiWyNCUNSs5CtMcGkyULqGYZRMCTC4fKj3emH\n3eWD3emH3dX54/R1uw1GZv2MhJDigirdDn2WE6KmDZ40K+RpVgRQgwOohlMYgnZPIdqt4SN6U2oW\nBOHMjs4lSUKz6yh2W/fiO+s+1NjrIkfjOqUWFw+ZgJLMMTjPOBo6lbbH95EJMuTrc5Gvz8UV+ZeG\nTxF4bZGQr7HXYVfrPuzCPgDhLwn5+tzIkXxx2nCkqQ2nfO8Ov/Ok8D7qakXohC9cxpQMfC9rHPJ0\nQ5GnG4p83VBkpWZ2+/IxUNj9foJk7CYEkrNdbFPiyMzSornFhkAogIAYgF8MRO6Hf4IIhDofFwMI\nhIKneF6wc194OyiGEJJCnaEsIiSFjoW0GH782GOdt+Kx50SzC/t0JFEGyauB5NVC7LyVvFqoJQN0\nKi30qSroUpXdfzRK6FKO3ZcJQvdw7hbU4W2np/cBuXKZgDSdCmlaFdK0agw16WBKU2PEUAPyTNrI\noDBnwIU6ewNq7fWotdeh3tEIv3jsvXVKLYrShmGEYTiK0gpRaMiHSq466fM8QS/22Y4djbf77ADC\nQTvMkI8S4xiUZI3FMH1+vwZiqkGGzbW7UNNehxp7HRocjd16QrJSM1GcNhzD9Plo99k7Q/wI7P7u\n/xaVMiVydTnI0w5Fnn4o8nW5yNXmDNj58i69db8z1E+QrP+pJmO72KbokSQJATEIX8gHb9AHb8gL\nb9DXue2FN+QL/0Qe63xOyAdf8IR9IR+CYjBqtQoQIBdkkMnkkAsyyAU5ZMffymSQCV37jt2PPEcW\nvpULMgiCDMcfb0pSeIpUeN5y19zk8Jzl4AnrWQgAVMeN2E5RdY2cVsCg0kMvT4cGaVCKBgj+VLi8\nQTg9gfCPO3DsfudPSDz7/5o1asWxsNapO29VSNeqYdCpkN75uDZF0e0Iu69//0JiCE2uI6i11+OQ\nvR619nq0eW2R/TJBhgJdHorShqHIMAw2nx3fWffhoP1Q5Ghcq9TgPONolGSOxXnG0dCrdD193Dk7\nsV2BUAD1HYdR216HGvsh1Njr4Ql6ur0mQ50eOerO0+ciT5sDkyYrJkffJ2Kon4F4+U+1vyVju9im\n7iRJgl8MRELXd1wYnxiy3Z9z6n1d//meKQEC1HI1UhRqpMjVUCvU0KWkQgoJUMmUUMqUUMoUUMq7\n7ivDj8s7H++8r5IpoZApoDrueUqZEiq5EgpBAUkUIEnhEdyiBIRECaIYPk8cEiWIUnhbFCWIEjpv\npe63nfu6nu8PhHDU6kaz1YVmS7j7PBDs/nuQywQMMWowPNcAo06N3EwNhmZqkZOpgVrZP6OqI4ui\neAJweQLocHfeHhf6oighvTO4DVp15H6aTgVlL6ts9uZc/v61++w4ZG9Arb0Oh+z1aOhoOqmbulDf\ndW58DAoNBQMWkKdrlyiJOOpqxWFnMzLUacjTDYVGqRmQ2s4GB8oRJSBfyA+7zwGHvyP84+uA3X9s\n2xVwnxTKZ9ulLBNk4SCWq5GmNmCIXI0URUrkseMDOkWeghSFGmq5GqmdtymKlPB+uRpqueqk86vn\n+gXM7Q3i0BEHaprbUdMUnk7l8kbv6B8Iz5POzdJGQntopha5WRqY0lOhkMui+qVSEITIvGykD2zX\n7tlKV6fhwuzv4cLs7wEIHw03OptQZ2+AVqnFuMwxUT0aPxcyQYZcXQ5ydTmxLuWcMdSj5PPPP8WV\nV17d5+dv27YVhYXDkZFhjGJVFGuiJMIZcHUGdDicO44La4/khtXZDrvfAV/o5EFUx1MI8kjIZqZm\ndDs6Tjk+lI97TK041b4UKGWKMx7oFC2iKKHZ4kJNsx01ndOojlhc3b6umNJTUDTUALlMgEwWnn8t\ni9zHKR4L/8hlAgQZIvdlggBBduy+UiHDkIxUDM3UIsOghixOfieJSClXYkTacIxIGx7rUgYVhnoU\ndF169UxC/cMP12DevFsZ6kmiw+9EvaMR9R2H0djRhHafHQ6fAx0BV6/d2gIE6FRaZKVmIk1lgEGl\nh0GtD9+q9EhTG2BQ6WBQGZCiUA9gi6LH4fZ3zoG2o6bJgUNHHPD6j3XbqlVyjC3MwIhcA4o750Ib\ntCcPwiIihnpUdF169ZVX/oLa2oPo6OhAKBTCfff9CiNHjsIbb/wVX3yxATKZDFOnTsN5543DV199\njkOHavH73z+JnJzE7wIaTLxBLxo7mlDXGeINjkZYjxs0BIRHzaap9BhuKIChM6zTjgtrg1qPNJUB\nRbk5aLP2fpGiRBYMiThsdqKmyYGaZjtqmxxobe8+QGlopiYc3nnhEM/LOvfFTIgGi6QP9aqDH+Db\n1p19fr5cJpx21OmF2d/DD0de1+P+efN+jKqqtyGTyXDJJZfi+utvwKFDtXj22T/gmWf+jLfeegPv\nvbcWcrkc7723GhdfPBkjR47GL3/5awZ6nAuKQTQ5j4SPwh2HUd/RiKOu1m7nsnWd5w+H6wtQaCjA\nMEM+9Epdn7q35bKBWb5yIPgDIbTYPDhidaHlXw3YddAcvrjHcQPPNGoFSkcYUZybhuI8A0YMNUCT\n0vtSpUTUs6QP9VjauXMH2tttWLfuHwAAn88LALjyyqtx3313YsaMazBzZv9eM536jyiJaHGbjwW4\noxFNzuZu81tVchVGphdhmCEfhfoCDDcUwJiSETfnp6NNFCVYHV60tLlxpM0dXnSlzY2jbW5YHb5u\nzxUEoMCkw4i8NBTnGjAi14AhRg3PWxP1o6QP9R+OvK7Xo+oT9eeIVqVSgV/84lcoLR3f7fH7738Q\n9fV1+OyzT3D33Uvwl7+81i+fN1h0Td1y+Jzo8Du7L3kpSZDQfVnM4/efuERmeDu8TKYECc6AuzPE\nG9HY0dRtTWm5IEeebigKDeEj8EJ9PnK02XExbzWaJEmC0xPA0c6wbmnzdN660WLznPLSlek6FcYO\nS0eOUYMhRg3OHzME6anyfltSlIhOjf/CoqDr0qvjxpXiyy8/R2npeBw6VIvq6o247rob8M47b2L+\n/EWYP38Rtm37Fm6365SXax0sAqEAXEE3nH4XnAEXXAEXnAH3sft+F1yd212PBaK4mAkQHrA2RGM6\nFuCGfOTpcqGUJd8/mWBIhC8Qgs8fgtMTQKvNc9JR96mmj6Wo5Mg3aZFj1ETCO3ybelJ4J+OaAkTx\nKPn+h4oDx196taXlKO68cyFEUcR9990PnU6H9nYbFi36CVJTNSgtHQ+DIQ0XXDAB//3fv8Fjjz2F\nESOKY92EfuMOuLHdvBt2vyMcyn53Z2i7Irenm7rVJUWuhlapRa52KLRKDfQaDfz+EGSRy0x2vwzl\nsfuyY5edPH4/ZJ23nY8LMqjlKgzT56FAn3/G62wPFFGUYG73oN3pgy8gwh8IwRcIwesPRe6Hf0T4\njnvMGwjB7+++3x8I9TqGRC4TYEpPxaj89Ehgd4W4QXvyfHQiii2uKHeCZD2iGOh2WT1t2ND4Nf55\nZDP8pwhtpUwBnVIHnVIDrVILnUobvlVqoFN23e96PPycE4+Sk/HP6vg2SZIEh8uPw2YXDpudnT8u\nHLG4ul2/uq8EACqVHGqlHClKOVRKOdQqGdRKeeQnVa3AkIzUyFF3VnpKZP3v/mpXsmCbEkeytYsr\nytGAqXM04NOGL/Ft605IkJCuTsPs4VejQJcHrSoc2Dql9pQXexjMfP4QmiwubK1pw95aSyTAT7wg\nh0IuIDdTizyTDplp6m6BrFZ1BrVSjpTI/WOhrVTIeGRNlOQY6nTOREnELsserG/4EjX2QwCAfF0u\nrh52OS7KPj+ppmmdq5AootXmCR99t4aPvpvMLpjbPSct8GpKT8Go/DTkmXTIN2mRb9JhiDG1X46c\niSg5MdTprPlDAVQf3YLPGr9Eq9sCABiXOQZXF1yOMRkjeVQIwNLuwdYDFjS0dOCw2Ylmi/uk0eK6\nVCXGDEtHvkmHsSOykJYqR16WliPFieiM8X8NOmMdfie+PLwRXzZtgjPggkKQY8rQizG9YFpSXBDh\nXNldfvx7Twuqv2tBTbMj8rhSIUOeSRs56s7vPAI/fsBZsp37I6KBxVCnPmtxteKzxq9QfXQLAmIQ\nGkUqZhVOxxX5lyJNbYh1eTHl8gawZZ8Zm/e0YE+9DZIUXmzlvMIMXDJuCEblp2FIhobLnRJRVDHU\nqVeSJKHGXof1DV9gp+U7AEBmihHTh03DlKEXQz2IB7z5/CFsO2hB9Xct2HXIimAofFa8ONeASeOG\nYNLYbKTpkuOiK0SUGBjqdEohMYRt5l34tOFL1Hc0AgCKDMNw9bArcL6pJOlXUetJMCRiV20bqve0\nYNsBC3yB8IJB+SYdLhmXjUnnDYEpQa5/TUTJh6FO3XiDXmw68g02NH4Fq9cGAQLON5WibNjlg/a6\nyKIoYV+DDdV7WrBlnzmyulp2eiomjRuCS8YNQV6WNsZVEhEx1Ac9SZLQ6rGgpr0ONfZD2G7eDU/Q\nA6VMiWl5UzC94DJka0yxLnPASZKE2iMOVH/Xgn/vbYXdGV5AJ12nwsyLC3DJuCEYnqPnCH8iiisM\n9UEmJIbQ6GzqDPE61LQfgjPgiuzXK3W4rmgmpuVNgU41+I4+D5udqP6uBZv3tMDcHr6qnjZFgSsu\nyMUl5w3B6IJ0DnYjorjFUE9ynqAXdfYGfHa0GTub9+GQowEB8dgqZenqNEwccgGK04ajOL0IQ7VD\nBtX5clGSUHekA1v3m/HtATOOWN0AALVSjsklQ3DJeUNQUmSEQj54fidElLgY6kmm3WePHIXXth/C\nYecRSJ1rlQkQMFQ7BMXpRZ0hPhzGlIwYVzzwgiER+xrbsXW/GdsOWGDrCF9eVaWQYcJoEyadl43z\nR2ZBreRKeESUWBjqCUyURLS4zahpP9TZlV4Hq7ctsl8hyDEirRDF6UWYMGwcMmGCRqmJYcWx4/OH\nsLPWim8PmLH9oBVuX3iwmzZFgamlOZgw2oRxRUYGORElNIZ6ArJ6bFhT+xH2WPfDFXRHHtcoUlGa\neR6K04ejOK0Iw/R5UMqVAAbnSmUdbj+2HbTg2/0W7K5rQ6DzymZGgxpTOoN8dEEa11InoqTBUE8g\nITGEDYe/xoe1H8MvBpChTse4zLGdIT4cOdrsQXU+/FQsdg++3W/B1v1m7D/cjq4LC+dlaXHh6CxM\nGG1C4RCOWiei5MRQTxD1jkas2rsah53N0Co1KB/zQ0zKmTDow0mSJDSZXdh6wIyt+81oaHFG9hXn\nGTBhlAkTRpswxDg4TzsQ0eDCUI9znqAXf69dhy8Pb4QECZNzJuLGkXMG5XSzLqIooabZjjWb6rFx\nezNa2z0AALlMQGmRERNGm3DBqCykc4lWIhpkGOpxSpIkbDfvwtv734fd78AQjQnlY36I0RnFsS4t\nJgJBEXvqbeER6wctcLjCi8GoVXJMHJuNCaOzMH5EFjQp/CtNRIMX/weMQ21eG97e/x52WvZAIchx\nbdEMzCy8CkrZ4Prj8viC2Flrxdb9ZuyoscLrD6+zrtcoMW38UFx58TDkZ6RAqeCIdSIigKEeV0Ji\nCF8c/if+fuhj+EN+jEofgXljfogh2uxYlzZg7C4/th0wY+t+C/bUt0WufJaVloLLz8/FhNEmjMxL\ng0wmDMoR/UREvYlqqC9fvhzbt2+HIAioqKjA+PHjI/vWr1+PF154ASqVCnPmzMGtt94KAFizZg1e\neuklKBQK3HPPPbjyyiujWWLcqHc04s29q9HYORDultE34JKciwbFQLhWmxtb91uw9YAZNYftnUvl\nAAXZOkwYbcKFo7JQkK0bFL8LIqJzEbVQ37x5M+rr61FZWYmamhpUVFSgsrISACCKIpYtW4Z3330X\n6enpWLRoEcrKyqBWq/H8889j9erVcLvdeO6555I+1D1BLz6oXYcvBtFAOEmS0NDijCzNetgcXnte\nEIBRBemYMCoLF4428RKmRERRhuWDAAAgAElEQVRnKGqhvmnTJpSVlQEAiouLYbfb4XQ6odPpYLPZ\nYDAYYDQaAQCTJ0/Gxo0bkZKSgilTpkCn00Gn02HZsmXRKi8ubDPvwjv730e7z45sTRbmjfkhRmeM\njHVZURESRRw8bMeW/WZ8u98CqyN8sRSFXIbzizNx4WgTLhiZBYNWFeNKiYgSV9RC3WKxoKSkJLJt\nNBphNpuh0+lgNBrhcrlQV1eHvLw8VFdXY9KkSQAAr9eLn/70p3A4HLj77rsxZcqUaJUYM+GBcO9j\np+W7pB8I12R24uN/N+LbAxY4PeELyaSqFZg8bggmjDahpMiIVHXytZuIKBYG7H9TqWtpLwCCIODx\nxx9HRUUF9Ho98vPzI/va29vxpz/9Cc3NzfjJT36CDRs29HouNSNDA0U/j342mfT9+n5dQmIIHx34\nHJW7/g5f0IeS7NFYdNE85BpyovJ5J4pWu07liMWFVR/vxRdbD0OSwkuzzr5gOCZ/byi+V5wFpaJ/\nVr4byDYNlGRsE5Cc7WKbEkeytutEUQv17OxsWCyWyHZraytMJlNke9KkSVi1ahUA4KmnnkJeXh68\nXi8uvPBCKBQKDBs2DFqtFm1tbcjMzOzxc2w2d4/7zka0RlQ3OA5j1b7VaOxoglapwdzz5oYHwvmE\nARnBPVAjxdscXqz5Zx2+3nEEoiShIFuHG6eNwPiRmZB1fjlrt7lO8y59k4yj35OxTUBytottShzJ\n1q7evqBEbaHwqVOnYt26dQCA3bt3Izs7GzqdLrJ/4cKFsFqtcLvd2LBhA6ZMmYLLLrsM//rXvyCK\nImw2G9xuNzIyEvvSoP5QAH/bvwZPfvMcGjuacEnORfjtJb/C5KETk2o0t93lx6r1+/HAin/hy+3N\nyM5IxU9/UIKH5l+MC0ZlRQKdiIiiJ2pH6hMmTEBJSQnKy8shCAIeeughVFVVQa/XY8aMGZg7dy4W\nLFgAQRCwePHiyKC5WbNmYe7cuQCA//7v/4Yswa+g9da+KlQf3ZK0A+Fc3gDWVjfgk28a4Q+IyEpL\nwfenFmFK6RBe/YyIaIAJ0vEnuxNQf3ep9Gc3zb+OfIPX97yNQn0BfjHhp5HLoMZCf3c/eXxBrP+m\nEWs3N8LjCyJNp8L3Lx2OaefnQiEfmDBPti41IDnbBCRnu9imxJFs7eqt+53DjqPkqKsFlfveRaoi\nBQtK/zOmgd6f/IEQPtvahH/8qx5OTwC6VCXmXjUS0yfkQaXkcq1ERLHEUI8CfyiAl3ethF8M4I5x\ntyAr1Rjrks5ZMCTiq+3N+PvGOrQ7/UhVy3HDtCLMmFjAKWlERHGC/xtHwd8OrEGz6yguz5uCCdnj\nT/+COCaKEjbtPor3vz4Ei90LlVKGaycX4ppLhkGXmhy9D0REyYKh3s++admGfzZXI1+Xix+OvC7W\n5Zw1UZKwZZ8Z731ViyNWNxRyAWUX5WPOlEKk8TrlRERxiaHej1rdFry5dzXUclXCnkeXJAk7aqx4\n98taNLQ6IRMEXH5+Lq6/dDgy01JiXR4REfWCod5PAmIQr+xeCW/Ih9vHzcMQjen0L4ozNc12vPXp\nAdQ0OSAAmFwyBD+4rAhDMjSxLo2IiPqAod5P3jv4IRo7mnDp0Itxcc6FsS7njIiihA821WHN13UQ\nJQkTRptww7Qi5Jt0p30tERHFD4Z6P9hm3oXPD/8TOdohuHn0D2Jdzhmx2r148e+7sf+wHUaDGouu\nG4cxwxJ7FT8iosGKoX6OrJ42vLHnHShlStxR8p9QyRPn0qGb97TgtbX74PEFMXGMCbfNHgttSuKN\nAyAiojCG+jkIiSG8snsVPEEP/nPszcjVDczV1s6V1x/EqvUH8PWOI1ApZZg/eywuGz80qdaiJyIa\njBjq52BN7VrUORpw8ZALMWXoxFiX0yd1Rx1Y8f5utNg8KByix+Lvj8PQTG2syyIion7AUD9Luyx7\nsL7hC2RrslA+5sa4P8oVRQkfVdej6otahEQJ11wyDD+8fMSArdNORETRx1A/CzZvO/5vTyUUMgUW\nlNyKFEV8z9+2dfjw7Ood2H7AgjSdCgvnjENJUeIvXUtERN0x1M9QSAzh1d1vwhVw45bRN6JAnxvr\nknr17QEzXv3HXjg9AVwwMgu3XzsWBk3iDOYjIqK+Y6ifoX/UrUeN/RAuNH0P0/Imx7qcHvkDIVRu\nOIgNW5ugVMjw0x+Ox8WjMuP+NAEREZ09hvoZ2Nt2AOvqPkNmihH/MfZHcRuQja1OrFizG80WF/JM\nWiz5fgkuHDc0qa4nTEREJ2Oo95Hd14G/fvcmZIIMd5T+JzTK1FiXdBJJkvDplsN4e0MNgiERV1+U\nj5uvLOZ1zomIBgmGeh+IkojXvnsTHX4nbhp5HQoNBbEu6SQOlx+v/GMPdtRYoUtVYsGcUlwwMivW\nZRER0QBiqPfBx/UbsM92EN/LGoerCqbFupyT7Kq14qUP98Dh8qOkyIg75pyHdF4elYho0GGon8bB\n9kP4oPZjZKjT8ePz5sbVefRAUMTqL2rw8b8bIZcJuGX6SMy4uACyOKqRiIgGDkO9F06/C6/uXgVB\nEDC/5D+gVcbPJUiPWF1Y8f5uNLQ6kWPUYMn3S1CYo491WUREFEMM9R6Ikoj/21OJdp8dPxgxG8Xp\nw2NdUoTF7sHv/+8beHwhXH5+LuZdPQpqFQfDERENdgz1HnzW+BV2W/fiPONolBVeEetyIiRJ6ryy\nWgi3zhyN6RPyY10SERHFCS78fQqH7PV4v+YjGFR63DauHDIhfn5NX+88gt2H2lA6woirLsyLdTlE\nRBRH4iet4oTT78Iru1dBkiTML5kHvUoX65IibB0+vPXpQaSo5Lht1ti4GrRHRESxx1A/jiRJ+N/N\nb6DNa8PsojKMzhgZ65IiJEnC6+v2weMLYu5VI5GZFt8XkSEiooHHUD/O183V2Ny0DaPSR2D28Ktj\nXU431XtasO2gBWOHpePyC+L7IjJERBQbDPXj1DsaYUxNx+0l8+LqPLrD5ceqTw5ApZTh9tljOQ+d\niIhOiaPfj/MfY29CRqYG9jZvrEvpZuUn++H0BDDv6lHIzoifufJERBRf4udwNA7IBBlUcmWsy+hm\ny75W/HtvK0bmpeHqizh9jYiIesZQj2NOTwCvf7wfCrkM868dC5mM3e5ERNQzhnoce+vTA3C4/Lhh\nWhGGZmpjXQ4REcU5hnqc2lFjwcZdR1GYo8esSfF3qVciIoo/DPU45PEF8drafZDLBNxx7XmQy/jH\nREREp8e0iEPvbDgIW4cPc6YUIj87fla0IyKi+BbVUF++fDluueUWlJeXY8eOHd32rV+/HjfddBPm\nzZuHN954o9s+r9eLsrIyVFVVRbO8uLSnrg2fb2tGnkmL6y4dHutyiIgogUQt1Ddv3oz6+npUVlbi\n0UcfxaOPPhrZJ4oili1bhhdffBErV67Ehg0bcPTo0cj+F154AWlpadEqLW75/CG8+tFeCAKw4Nrz\noJCzI4WIiPouaqmxadMmlJWVAQCKi4tht9vhdDoBADabDQaDAUajETKZDJMnT8bGjRsBADU1NTh4\n8CCuvPLKaJUWt1Z/WQOL3YtrLhmGoqGGWJdDREQJJmqhbrFYkJGREdk2Go0wm82R+y6XC3V1dQgE\nAqiurobFYgEAPPHEE3jggQeiVVbcOnC4HZ9+cxg5Rg1+MLUo1uUQEVECGrBlYiVJitwXBAGPP/44\nKioqoNfrkZ8fXintvffewwUXXICCgr5P4crI0EChkPdrrSaTvl/f73R8gRD+7+VqQAB+8R8TkJeb\nHpXPGeh2DQS2KXEkY7vYpsSRrO06UdRCPTs7O3L0DQCtra0wmUyR7UmTJmHVqlUAgKeeegp5eXn4\n5JNP0NjYiM8//xxHjx6FSqVCTk4OLr300h4/x2Zz92vdJpMeZnNHv77n6bzz+UE0mV0om5gPk04V\nlc+PRbuijW1KHMnYLrYpcSRbu3r7ghK17vepU6di3bp1AIDdu3cjOzsbOt2x6VkLFy6E1WqF2+3G\nhg0bMGXKFDzzzDNYvXo13n77bdx888248847ew30ZHDoiANrqxuQlZaCmy4vjnU5RESUwKJ2pD5h\nwgSUlJSgvLwcgiDgoYceQlVVFfR6PWbMmIG5c+diwYIFEAQBixcvhtFojFYpcSsYEvHKP/ZAkoD5\ns8dCrerf0whERDS4RPWc+v33399te+zYsZH7M2fOxMyZM3t87d133x21uuLFBxvr0GR24coLcnHe\n8MH3pYaIiPoXJ0LHSGOrEx9uqkeGXo2brxoZ63KIiCgJMNRjICSKeOXDPQiJEm67ZixS1QM2CYGI\niJIYQz0G1lY3oL6lA1NLczC+ODPW5RARUZJgqA+wZosL739dhzStCrdcPSrW5RARURJhqA8gUZTw\n6kd7EAyJuHXmGOhSlbEuiYiIkghDfQCt33IYNU0OXDw2GxeNMZ3+BURERGeAoT5AWm1uVH1RA12q\nEv85Y3SsyyEioiTEUB8AoiThrx/thT8o4j9mjIJBq4p1SURElIQY6gPgy23N2NvQjgtGZuGS84bE\nuhwiIkpSDPUoa3N48faGg0hVK/DjWWMgCEKsSyIioiTFUI+yLfvM8PpDuHFaETL06liXQ0RESYyh\nHmXmdg8AYGR+WowrISKiZMdQjzKL3QsAyEpLjXElRESU7BjqUWaxe6FWyaFN4fruREQUXQz1KJIk\nCRa7B6a0FA6QIyKiqGOoR5HLG4TXH2LXOxERDQiGehRZO8+nZ6alxLgSIiIaDBjqUdQ18t3EUCci\nogHAUI8iS+RInd3vREQUfQz1KLLYw0fqWTxSJyKiAcBQj6KuI3VTOkOdiIiij6EeRVa7F6lqBTQp\nyliXQkREgwBDPUokSYK5c446ERHRQOhTqEuSFO06kk6HJwB/QOR0NiIiGjB9CvWrrroKTz/9NBob\nG6NdT9Kwcs13IiIaYH0K9XfeeQcmkwkVFRWYP38+/v73v8Pv90e7toTWNUc9i4PkiIhogPQp1E0m\nE2699Va8/vrrePjhh/Hmm29i2rRpePrpp+Hz+aJdY0I6dqTOUCciooHR54Fy//73v/Hggw9i0aJF\nmDBhAlatWgWDwYB77703mvUlLF5ylYiIBlqfrgc6Y8YM5OXlYe7cufjd734HpTI8Rau4uBjr16+P\naoGJysyFZ4iIaID1KdRfeuklSJKE4cOHAwC+++47jBs3DgCwatWqqBWXyKx2L7QpCqSqeR11IiIa\nGH3qfq+qqsKKFSsi23/5y1/whz/8AQB4nfBTCF9H3cuudyIiGlB9CvXq6mo89thjke1nnnkGW7Zs\niVpRic7h8iMQFDnynYiIBlSfQj0QCHSbwuZyuRAMBqNWVKKzcOQ7ERHFQJ9O+JaXl+Paa69FaWkp\nRFHEzp078fOf/zzatSWsY4Pk2P1OREQDp0+hfvPNN2Pq1KnYuXMnBEHAgw8+CJ1OF+3aEhbnqBMR\nUSz0eZ662+2G0WhERkYGamtrMXfu3GjWldDY/U5ERLHQpyP13//+9/jnP/8Ji8WCYcOGobGxEQsW\nLDjt65YvX47t27dDEARUVFRg/PjxkX3r16/HCy+8AJVKhTlz5uDWW28FADz55JPYsmULgsEglixZ\ngpkzZ55l02LH0s7udyIiGnh9CvWdO3fio48+wo9//GO8/vrr2LVrFz755JNeX7N582bU19ejsrIS\nNTU1qKioQGVlJQBAFEUsW7YM7777LtLT07Fo0SKUlZWhrq4OBw4cQGVlJWw2G2688cbEDHW7F3qN\nEmqVPNalEBHRINKn7neVSgUgPApekiSUlpZi69atvb5m06ZNKCsrAxBeec5ut8PpdAIAbDYbDAYD\njEYjZDIZJk+ejI0bN+Liiy/Gs88+CwAwGAzweDwIhUJn3bhYECUJVoeXXe9ERDTg+hTqRUVFWLly\nJSZOnIj58+fjkUceQUdHR6+vsVgsyMjIiGwbjUaYzebIfZfLhbq6OgQCAVRXV8NisUAul0Oj0QAA\n/va3v+Hyyy+HXJ5YR7t2px/BkMSudyIiGnB96n5/5JFHYLfbYTAY8OGHH8JqtWLJkiVn9EGSJEXu\nC4KAxx9/HBUVFdDr9cjPz+/23PXr1+Nvf/sbXnnlldO+b0aGBgpF/wa/yaQ/69eaneH5/MOGGs7p\nfaIh3urpD2xT4kjGdrFNiSNZ23WiPoX68uXLsXTpUgDA9ddf36c3zs7OhsViiWy3trbCZDJFtidN\nmhRZN/6pp55CXl4eAOCrr77C//7v/+Kll16CXn/6PwSbzd2nevrKZNLDbO69F6I3B+vaAAAalfyc\n3qe/nWu74hHblDiSsV1sU+JItnb19gWlT93vcrkcmzZtgs/ngyiKkZ/eTJ06FevWrQMA7N69G9nZ\n2d3mti9cuBBWqxVutxsbNmzAlClT0NHRgSeffBIrVqxAenp6X0qLOxZenY2IiGKkT0fq77zzDl57\n7bWTutD37NnT42smTJiAkpISlJeXQxAEPPTQQ6iqqoJer8eMGTMwd+5cLFiwAIIgYPHixTAajZFR\n7/fdd1/kfZ544gnk5uaeQxMHFueoExFRrAjS8UmdgPq7S+Vcu2n+581vsafehv/9ryugUsbPIL9k\n634C2KZEkoztYpsSR7K1q7fu9z4dqXdNMzvRvffee3YVJTGL3YM0rSquAp2IiAaHPp9T7/oRRRHV\n1dWnndI2GImihDaHj13vREQUE306Uj/ximyhUAh33313VApKZLYOH0KihKx0zlEnIqKB1+cLuhwv\nGAyioaGhv2tJeBz5TkREsdSnI/UrrrgCgiBEtu12O2688caoFZWouka+ZzLUiYgoBvoU6l2LxADh\nqWw6nQ4GgyFqRSWqrlA3cYlYIiKKgT51v3s8Hrz11lvIy8tDbm4uHnvsMRw4cCDatSUcdr8TEVEs\n9SnUH3nkEVxxxRWR7Ztuugm/+93volZUorK0eyEAMBoY6kRENPD6FOqhUAgTJ06MbE+cOBEJvmZN\nVFjsXqTr1VAqzmr8IRER0Tnp0zl1vV6PVatW4ZJLLoEoivjqq6+g1WqjXVtCCYkibB0+jMjjWAMi\nIoqNPoX6Y489hqeeegpvvvkmgPC67o899lhUC0s0bQ4fREmCiefTiYgoRvoU6kajEYsWLcLw4cMB\nAN999x2MRmM060o4x6azceQ7ERHFRp9O/j799NNYsWJFZPsvf/kL/vCHP0StqERkaefIdyIiiq0+\nhXp1dXW37vZnnnkGW7ZsiVpRiejYHHWGOhERxUafQj0QCMDv90e2XS4XgsFg1IpKRJHud677TkRE\nMdKnc+rl5eW49tprUVpaClEUsXPnTtx2223Rri2hWOweCAJg1KtjXQoREQ1SfQr1m2++GcOHD4fN\nZoMgCJg+fTpWrFiB22+/PcrlJQ6L3QujXg2FnHPUiYgoNvoU6o8++ii+/vprWCwWDBs2DI2NjViw\nYEG0a0sYwZCI9g4fRhWkx7oUIiIaxPp0WLljxw589NFHGDt2LFavXo1XXnkFHo8n2rUlDKvDCwkc\nJEdERLHVp1BXqVQAwgPmJElCaWkptm7dGtXCEgkvuUpERPGgT93vRUVFWLlyJSZOnIj58+ejqKgI\nHR0d0a4tYVg7Qz2LC88QEVEM9SnUH3nkEdjtdhgMBnz44YewWq1YsmRJtGtLGObOhWdM6TxSJyKi\n2OlTqAuCgPT08CCw66+/PqoFJSIru9+JiCgOcP5VPzDbPZAJAjI4R52IiGKIod4PLHYvjAY15DL+\nOomIKHaYQucoEAzB7vTzQi5ERBRzDPVz1DWdLYtrvhMRUYwx1M/RselsPFInIqLYYqifIwtDnYiI\n4gRD/RyZ7eE56lx4hoiIYo2hfo7Y/U5ERPGCoX6OzO1eyGUC0nWco05ERLHFUD9HVrsHmWkpkMmE\nWJdCRESDHEP9HPgCITjcAXa9ExFRXGConwOOfCcionjCUD8HVo58JyKiOBLVUF++fDluueUWlJeX\nY8eOHd32rV+/HjfddBPmzZuHN954o0+viTc8UicionjSp0uvno3Nmzejvr4elZWVqKmpQUVFBSor\nKwEAoihi2bJlePfdd5Geno5FixahrKwMDQ0NPb4mHlnauUQsERHFj6iF+qZNm1BWVgYAKC4uht1u\nh9PphE6ng81mg8FggNFoBABMnjwZGzduRGNjY4+viUeWSPc7j9SJiCj2ohbqFosFJSUlkW2j0Qiz\n2QydTgej0QiXy4W6ujrk5eWhuroakyZN6vU1PcnI0EChkPdr7SaTvk/Pa3f5oVTIUFyYmRBT2vra\nrkTCNiWOZGwX25Q4krVdJ4paqJ9IkqTIfUEQ8Pjjj6OiogJ6vR75+fmnfU1PbDZ3v9UIhP/gzeaO\nPj33qNWNTEMKrFZnv9YQDWfSrkTBNiWOZGwX25Q4kq1dvX1BiVqoZ2dnw2KxRLZbW1thMpki25Mm\nTcKqVasAAE899RTy8vLg8/l6fU088fiCcHoCGJ4zOL79ERFR/Iva6PepU6di3bp1AIDdu3cjOzu7\nWzf6woULYbVa4Xa7sWHDBkyZMuW0r4knXPOdiIjiTdSO1CdMmICSkhKUl5dDEAQ89NBDqKqqgl6v\nx4wZMzB37lwsWLAAgiBg8eLFMBqNMBqNJ70mXkWms3HkOxERxYmonlO///77u22PHTs2cn/mzJmY\nOXPmaV8TrzjynYiI4g1XlDtLXUfqmQx1IiKKEwz1s9QV6iYuEUtERHGCoX6WLHYPVEoZ9BplrEsh\nIiICwFA/a5Z2L7LSUiEI8b/oDBERDQ4M9bPg9gbg9gU5SI6IiOIKQ/0scJAcERHFI4b6WeAgOSIi\nikcM9bPA66gTEVE8YqifBUt7eOEZdr8TEVE8YaifhUj3O5eIJSKiOMJQPwsWuxdqlRzalAG7ci0R\nEdFpMdTPkCRJsNg9MKWlcI46ERHFFYb6GXJ5g/D6Q8jiyHciIoozDPUz1HV1Ng6SIyKieMNQP0OW\n9q456gx1IiKKLwz1M3RsNTl2vxMRUXxhqJ+hru53LjxDRETxhqF+ho7NUWeoExFRfGGonyGr3YtU\ntQKaFF5HnYiI4gtD/QxIkgSz3cOudyIiiksM9TPQ4QnAHxAZ6kREFJcY6mfAGrk6G0e+ExFR/GGo\nnwFz59XZsjhIjoiI4hBD/QxYeR11IiKKYwz1M2Bm9zsREcUxhvoZ4MIzREQUzxjqZ8Bq90KbokCq\nmtdRJyKi+MNQ76PwddS97HonIqK4xVDvI4fLj0BQ5Mh3IiKKWwz1PrJw5DsREcU5hnofmSOD5Nj9\nTkRE8Ymh3keco05ERPGOod5H5naGOhERxTeGeh9Z2f1ORERxjqHeRxa7F3qNEmqVPNalEBERnVJU\nV1FZvnw5tm/fDkEQUFFRgfHjx0f2rVy5EmvWrIFMJkNpaSmWLl2KlpYWVFRUwO/3QxRFPPjggygt\nLY1miX0iShKsDi8KsnWxLoWIiKhHUQv1zZs3o76+HpWVlaipqUFFRQUqKysBAE6nEy+//DI+/vhj\nKBQKLFiwANu2bcO6deswY8YMlJeXY+vWrXj66afx8ssvR6vEPrM7/QiGJHa9ExFRXIta9/umTZtQ\nVlYGACguLobdbofT6QQAKJVKKJVKuN1uBINBeDwepKWlISMjA+3t7QAAh8OBjIyMaJV3RrjmOxER\nJYKoHalbLBaUlJREto1GI8xmM3Q6HdRqNe666y6UlZVBrVZjzpw5KCoqwu23344f/ehHeO+99+B0\nOvHmm29Gq7wzYuHIdyIiSgADdmUSSZIi951OJ1asWIG1a9dCp9Phtttuw969e/HZZ59h9uzZ+NnP\nfoYNGzbgiSeewJ/+9Kde3zcjQwOFon8Hr5lM+m7bnmAzAKC40HjSvkSSyLX3hG1KHMnYLrYpcSRr\nu04UtVDPzs6GxWKJbLe2tsJkMgEAampqUFBQAKPRCACYOHEidu3aha1bt+K+++4DAEydOhWPPPLI\naT/HZnP3a90mkx5mc0e3x+qb7QAAJaST9iWKU7Ur0bFNiSMZ28U2JY5ka1dvX1Cidk596tSpWLdu\nHQBg9+7dyM7Ohk4XHj2el5eHmpoaeL3hbu1du3Zh+PDhKCwsxPbt2wEAO3bsQGFhYbTKOyNd675n\nGtj9TkRE8StqR+oTJkxASUkJysvLIQgCHnroIVRVVUGv12PGjBm444478JOf/ARyuRwXXnghJk6c\niGHDhmHp0qVYu3YtAGDp0qXRKu+MWOwepGlVUCk5R52IiOJXVM+p33///d22x44dG7lfXl6O8vLy\nbvuzs7Px4osvRrOkMyaKEtocPgzPGRznY4iIKHFxRbnTsHX4EBIlZKVzjjoREcU3hvppcI46EREl\nCob6aUQGyTHUiYgozjHUT6Mr1E1cIpaIiOIcQ/002P1ORESJgqF+GpZ2LwQARs5RJyKiOMdQPw2L\n3Yt0vRpKBX9VREQU35hUvQiGRLR1eDlIjoiIEgJDvRe2Dh8kCTAx1ImIKAEw1HtxbDobR74TEVH8\nY6j3wtLOke9ERJQ4GOq9ODZHnaFORETxj6Hei0j3O9d9JyKiBMBQ74XF7oEgAEa9OtalEBERnRZD\nvRcWuxdGvRoKOX9NREQU/5hWPQgERbR3+DjynYiIEgZDvQdtHV5I4Mh3IiJKHAz1HnQNkmOoExFR\nomCo9+DYHHV2vxMRUWJgqPcgMkc9nUfqRESUGBjqPbBGlohlqBMRUWJgqPfAbPdAJgjI4Bx1IiJK\nEAz1HljsXhgNashl/BUREVFiYGKdQiAYgt3p58h3IiJKKAz1Uzg2nY0j34mIKHEw1E+ha5BcFke+\nExFRAmGon4KZC88QEVECYqifgsXOhWeIiCjxMNRPwcojdSIiSkAM9VMwt3shlwlI13GOOhERJQ6G\n+ilY7R5kpqVAJhNiXQoREVGfMdRP4PUH4XAH2PVOREQJh6F+gtY2NwCeTyciosTDUD9Bq40j34mI\nKDEx1E/QYnUB4JE6EQrsr7wAAA12SURBVBElHob6CVp4pE5ERAlKEc03X758ObZv3w5BEFBRUYHx\n48dH9q1cuRJr1qyBTCZDaWkpli5dCgB4+eWXsWbNGigUCjz00EPdXjMQIufUuUQsERElmKiF+ubN\nm1FfX4/KykrU1NSgoqIClZWVAACn04mXX34ZH3/8MRQKBRYsWIBt27ZBq9Xiww8/xOrVq7Fv3z58\n+umnAx7qLW0uKOQyGLSqAf1cIiKicxW1UN+0aRPKysoAAMXFxbDb7XA6ndDpdFAqlVAqlXC73dBo\nNPB4PEhLS8Mnn3yC2bNnQ6FQoKSkBCUlJdEqr0ctbR5kpaVAJnCOOhERJZaohbrFYukWykajEWaz\nGTqdDmq1GnfddRfKysqgVqsxZ84cFBUVoampCXK5HHfccQeCwSAefPBBjB07ttfPycjQQKGQ90vN\nbm8AHW4/RhWkw2TS98t7xhO2KTEkY5uA5GwX25Q4krVdJ4rqOfXjSZIUue90OrFixQqsXbsWOp0O\nt912G/bu3QtJkhAKhfDSSy9hy5YtWLp0KVavXt3r+9ps7n6r8XCrEwBgSFXAbO7ot/eNByaTnm1K\nAMnYJiA528U2JY5ka1dvX1CiFurZ2dmwWCyR7dbW1v/f3r3HVF3/cRx/HrkIR4mbgFgZydLMyCDA\nCz+PSmnp1s0/SorIDZepaGMqYlNhY4IImQ5dpUUZ4HIRa3ab1rpYiWTqIGBNxbVAixDygmEG+/7+\nYJ1AwEu/H55zvrwe/32/n/Pd3u99Pl/efD7fG0FBQQDU1dVx6623EhAQAEB0dDTV1dUMGzaMUaNG\nYbFYiI6O5uTJk/0VXq9O27+jrjvfRUTE9fTbI21xcXHs2bMHgJqaGoKDgxk6dCgAN998M3V1dVy8\n2FlEq6urCQsLw2az8c033wCdhT80NLS/wuvVP59c1Z3vIiLievptph4VFcW4ceOYO3cuFouFjIwM\nysrK8PHxYcaMGSQnJ5OUlISbmxuRkZFER0cDsG/fPp588kkA1q5d21/h9ervmXqgirqIiLggi9H1\nYrcL+n9eJ9lS9gOHjzaxacl/TPdIm9muKYFyciVmzEs5uQ6z5XWla+p6o1wXN1k9uDloKD5WD0eH\nIiIict1u2N3vriDxwTEMG+ZDS3Oro0MRERG5bpqpdzHIYsFtkF46IyIirklFXURExCRU1EVERExC\nRV1ERMQkVNRFRERMQkVdRETEJFTURURETEJFXURExCRU1EVERExCRV1ERMQkVNRFRERMQkVdRETE\nJFz+06siIiLSSTN1ERERk1BRFxERMQkVdREREZNQURcRETEJFXURERGTUFEXERExCXdHB+Ao2dnZ\nVFZWYrFYePHFF7nnnnvsbfv372fjxo24ublhs9lYvHixAyO9Phs2bODQoUO0t7ezYMECZs6caW+L\nj49n+PDhuLm5AZCfn09ISIijQr0mFRUVvPDCC9xxxx0AjB49mjVr1tjbXbWv3n33XXbv3m3frq6u\n5siRI/btcePGERUVZd9+66237P3mjI4ePcqiRYuYN28eiYmJ/PLLL6SlpdHR0UFQUBB5eXl4enp2\nO+ZK56Az6C2nVatW0d7ejru7O3l5eQQFBdl/f7Wx6gwuzyk9PZ2amhr8/PwASE5OZtq0ad2OcfZ+\ngp55LV26lN9//x2AM2fOcO+995KVlWX/fVlZGZs3b2bkyJEATJ48mYULFzok9v87YwCqqKgwnnvu\nOcMwDOP48ePGE0880a191qxZxqlTp4yOjg4jISHBOHbsmCPCvG7l5eXG/PnzDcMwjJaWFmPq1Knd\n2qdPn260trY6ILJ/78CBA8aSJUv6bHfVvuqqoqLCyMzM7LYvNjbWQdFcvwsXLhiJiYnG6tWrjaKi\nIsMwDCM9Pd34+OOPDcMwjJdeeskoKSnpdszVzkFH6y2ntLQ046OPPjIMwzCKi4uN3Nzcbsdcbaw6\nWm85rVy50vj888/7PMbZ+8kwes+rq/T0dKOysrLbvvfee89Yv379jQrxhhqQy+/l5eU88MADAISH\nh3P27FlaW1sBqK+vx9fXl9DQUAYNGsTUqVMpLy93ZLjXLCYmhs2bNwNw00030dbWRkdHh4Oj6j+u\n3Fddbd26lUWLFjk6jH/N09OT7du3ExwcbN9XUVHB/fffD8D06dN79MuVzkFn0FtOGRkZPPjggwD4\n+/tz5swZR4X3r/SW09U4ez/BlfM6ceIE58+fd8rVhf4yIIv66dOn8ff3t28HBATQ1NQEQFNTEwEB\nAb22OTs3NzesVisApaWl2Gy2Hku2GRkZJCQkkJ+fj+EiLxM8fvw4zz//PAkJCXz77bf2/a7cV3+r\nqqoiNDS02zIuwKVLl1i2bBlz587lzTffdFB018bd3R0vL69u+9ra2uzL7YGBgT365UrnoDPoLSer\n1YqbmxsdHR3s3LmThx9+uMdxfY1VZ9BbTgDFxcUkJSWRmppKS0tLtzZn7yfoOy+At99+m8TExF7b\nvvvuO5KTk3n22Wepra3tzxBvqAF7Tb0rVylu1+qzzz6jtLSUwsLCbvuXLl3KlClT8PX1ZfHixezZ\ns4eHHnrIQVFem7CwMFJSUpg1axb19fUkJSWxd+/eHtdnXVVpaSmPP/54j/1paWk88sgjWCwWEhMT\niY6OJiIiwgER/u+u5fxylXOwo6ODtLQ0Jk6cyKRJk7q1ueJYffTRR/Hz82Ps2LFs27aNLVu2sHbt\n2j5/7yr9BJ3/GB86dIjMzMwebePHjycgIIBp06Zx5MgRVq5cyQcffHDjg+wHA3KmHhwczOnTp+3b\nv/32m32mdHlbY2PjdS1XOdrXX3/Nq6++yvbt2/Hx8enW9thjjxEYGIi7uzs2m42jR486KMprFxIS\nwuzZs7FYLIwcOZJhw4bR2NgIuH5fQecydWRkZI/9CQkJDBkyBKvVysSJE12ir7qyWq1cvHgR6L1f\nrnQOOrNVq1Zx2223kZKS0qPtSmPVWU2aNImxY8cCnTfSXj7OXLWfAA4ePNjnsnt4eLj9hsDIyEha\nWlpMc6lyQBb1uLg49uzZA0BNTQ3BwcEMHToUgFtuuYXW1lYaGhpob2/niy++IC4uzpHhXrPz58+z\nYcMGXnvtNfvdrF3bkpOTuXTpEtA54P++S9eZ7d69mzfeeAPoXG5vbm6237Hvyn0FncVuyJAhPWZy\nJ06cYNmyZRiGQXt7O4cPH3aJvupq8uTJ9nNs7969TJkypVv7lc5BZ7V79248PDxYunRpn+19jVVn\ntWTJEurr64HOfzAvH2eu2E9/++GHH7jzzjt7bdu+fTsffvgh0HnnfEBAgFM/XXI9BuxX2vLz8/n+\n+++xWCxkZGRQW1uLj48PM2bM4ODBg+Tn5wMwc+ZMkpOTHRzttdm1axcFBQXcfvvt9n0TJkxgzJgx\nzJgxgx07dvD+++8zePBg7rrrLtasWYPFYnFgxFfX2trK8uXLOXfuHH/99RcpKSk0Nze7fF9B52Ns\nmzZt4vXXXwdg27ZtxMTEEBkZSV5eHgcOHGDQoEHEx8c79eM21dXV5ObmcvLkSdzd3QkJCSE/P5/0\n9HT+/PNPRowYQU5ODh4eHqSmppKTk4OXl1ePc7CvP8CO0FtOzc3NDB482F7UwsPDyczMtOfU3t7e\nY6xOnTrVwZn8o7ecEhMT2bZtG97e3litVnJycggMDHSZfoLe8yooKKCgoID77ruP2bNn23+7cOFC\nXnnlFX799VdWrFhh/8fZWR/V+zcGbFEXERExmwG5/C4iImJGKuoiIiImoaIuIiJiEirqIiIiJqGi\nLiIiYhIq6iLSb8rKyli+fLmjwxAZMFTURURETELvfhcRioqK+OSTT+jo6GDUqFHMnz+fBQsWYLPZ\n+PHHHwF4+eWXCQkJ4csvv2Tr1q14eXnh7e1NVlYWISEhVFZWkp2djYeHB76+vuTm5gL/vECorq6O\nESNGsGXLFqd/6ZGIq9JMXWSAq6qq4tNPP6WkpIRdu3bh4+PD/v37qa+vZ86cOezcuZPY2FgKCwtp\na2tj9erVFBQUUFRUhM1mY9OmTQCsWLGCrKwsiouLiYmJ4auvvgI6v1yWlZVFWVkZx44do6amxpHp\nipiaZuoiA1xFRQU///wzSUlJAPzxxx80Njbi5+fH3XffDUBUVBQ7duzgp59+IjAwkOHDhwMQGxvL\nO++8Q0tLC+fOnWP06NEAzJs3D+i8ph4REYG3tzfQ+dGT8+fP3+AMRQYOFXWRAc7T05P4+Phun9xs\naGhgzpw59m3DMLBYLD2Wzbvu7+uN05d/KENvphbpP1p+FxngoqKi2LdvHxcuXACgpKSEpqYmzp49\nS21tLQCHDx9mzJgxhIWF0dzczKlTpwAoLy9n/Pjx+Pv74+fnR1VVFQCFhYWUlJQ4JiGRAUwzdZEB\nLiIigqeffppnnnmGwYMHExwczIQJEwgJCaGsrIz169djGAYbN27Ey8uLdevWkZqaiqenJ1arlXXr\n1gGQl5dHdnY27u7u+Pj4kJeXx969ex2cncjAoq+0iUgPDQ0NPPXUU+zbt8/RoYjIddDyu4iIiElo\npi4iImISmqmLiIiYhIq6iIiISaioi4iImISKuoiIiEmoqIuIiJiEirqIiIhJ/BdT0+8cKdMqrgAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMJD/ANK9tBEKmUqdgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}