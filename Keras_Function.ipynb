{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Function.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjhool/Deep-Learning-with-Keras/blob/master/Keras_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QAXv4SJXq9-T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# CNN Visualization\n",
        "\n",
        "### https://github.com/keplr-io/quiver "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LITvJLJSk2Aj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Activation\n",
        "\n",
        "inputs = Input(shape=(784,))\n",
        "\n",
        "x = Dense(32)(inputs)\n",
        "x = Activation(\"sigmoid\")(x)\n",
        "x = Dense(10)(x)\n",
        "predictions = Activation(\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aDy4RParqW1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# writing your own keras layers "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q5gcG0FtlD4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Activation\n",
        "\n",
        "input1 = Input(shape=(784,))\n",
        "input2 = Input(shape=(784,))\n",
        "\n",
        "x = Dense(32)(input1)\n",
        "x = Activation(\"sigmoid\")(x)\n",
        "x = Dense(10)(x)\n",
        "output1 = Activation(\"softmax\")(x)\n",
        "\n",
        "x = Dense(32)(input2)\n",
        "x = Activation(\"sigmoid\")(x)\n",
        "x = Dense(10)(x)\n",
        "output2 = Activation(\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=[output1, output2])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "© 2019 GitHub, Inc."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OS3mZCGeletV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# UCI ML DataSet Air Quality \n",
        "\n",
        "#  http://archive.ics.uci.edu/ml/datasets/air+quality  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_m92i1WlpAn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import division, print_function\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "DATA_DIR = \"../data\"\n",
        "\n",
        "AIRQUALITY_FILE = os.path.join(DATA_DIR, \"AirQualityUCI.csv\")\n",
        "\n",
        "aqdf = pd.read_csv(AIRQUALITY_FILE, sep=\";\", decimal=\",\", header=0)\n",
        "# remove first and last 2 cols \n",
        "del aqdf[\"#Date\"]\n",
        "del aqdf[\"Time\"]\n",
        "del aqdf[\"Unnamed: 15\"]\n",
        "del aqdf[\"Unnamed: 16\"]\n",
        "# fill NaNs in each column with the mean value\n",
        "aqdf = aqdf.fillna(aqdf.mean())\n",
        "# aqdf.head()\n",
        "\n",
        "Xorig = aqdf.as_matrix()\n",
        "Xorig.shape\n",
        "\n",
        "scaler = StandardScaler()\n",
        "Xscaled = scaler.fit_transform(Xorig)\n",
        "# store these off for predictions with unseen data\n",
        "Xmeans = scaler.mean_\n",
        "Xstds = scaler.scale_\n",
        "\n",
        "y = Xscaled[:, 3]\n",
        "X = np.delete(Xscaled, 3, axis=1)\n",
        "\n",
        "print(X.shape, y.shape, Xmeans.shape, Xstds.shape)\n",
        "\n",
        "train_size = int(0.7 * X.shape[0])\n",
        "Xtrain, Xtest, ytrain, ytest = X[0:train_size], X[train_size:], y[0:train_size], y[train_size:]\n",
        "print(Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape)\n",
        "\n",
        "# define the network\n",
        "readings = Input(shape=(12,))\n",
        "x = Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")(readings)\n",
        "benzene = Dense(1, kernel_initializer=\"glorot_uniform\")(x)\n",
        "\n",
        "model = Model(inputs=[readings], outputs=[benzene])\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "# train network\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "history = model.fit(Xtrain, ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
        "                   validation_split=0.2)\n",
        "\n",
        "# show some predictions\n",
        "ytest_ = model.predict(Xtest).flatten()\n",
        "for i in range(10):\n",
        "    label = (ytest[i] * Xstds[3]) + Xmeans[3]\n",
        "    prediction = (ytest_[i] * Xstds[3]) + Xmeans[3]\n",
        "    print(\"Benzene Conc. expected: {:.3f}, predicted: {:.3f}\".format(label, prediction))\n",
        "    \n",
        "# plot all predictions\n",
        "plt.plot(np.arange(ytest.shape[0]), (ytest * Xstds[3]) / Xmeans[3], \n",
        "         color=\"b\", label=\"actual\")\n",
        "plt.plot(np.arange(ytest_.shape[0]), (ytest_ * Xstds[3]) / Xmeans[3], \n",
        "         color=\"r\", alpha=0.5, label=\"predicted\")\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"C6H6 concentrations\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VRi9gJhMn_RC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbUHzcKBmrfZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# AutoEncoder   -- 협업 필터링( Dense), Remove Eyeglasses from Faces ( CNN ) ,  RNN \n",
        "\n",
        "# Deep Patients ( RNN ) , Skip Thought Vectors ( RNN)-- https://papers.nips.cc/paper/5950-skip-thought-vectors.pdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7v0CKDGwoDci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sentence Vector "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0oLLQGG2n_8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Deep Dream \n",
        "\n",
        "# https://github.com/google/deepdream \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bw5aYC4JpNZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import division, print_function\n",
        "from keras import backend as K\n",
        "from keras.applications import vgg16\n",
        "from keras.layers import Input\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess(img):\n",
        "    img4d = img.copy()\n",
        "    img4d = img4d.astype(\"float64\")\n",
        "    if K.image_dim_ordering() == \"th\":\n",
        "        # (H, W, C) -> (C, H, W)\n",
        "        img4d = img4d.transpose((2, 0, 1))\n",
        "    img4d = np.expand_dims(img4d, axis=0)\n",
        "    img4d = vgg16.preprocess_input(img4d)\n",
        "    return img4d\n",
        "\n",
        "def deprocess(img4d):\n",
        "    img = img4d.copy()\n",
        "    if K.image_dim_ordering() == \"th\":\n",
        "        # (B, C, H, W)\n",
        "        img = img.reshape((img4d.shape[1], img4d.shape[2], img4d.shape[3]))\n",
        "        # (C, H, W) -> (H, W, C)\n",
        "        img = img.transpose((1, 2, 0))\n",
        "    else:\n",
        "        # (B, H, W, C)\n",
        "        img = img.reshape((img4d.shape[1], img4d.shape[2], img4d.shape[3]))\n",
        "    img[:, :, 0] += 103.939\n",
        "    img[:, :, 1] += 116.779\n",
        "    img[:, :, 2] += 123.68\n",
        "    # BGR -> RGB\n",
        "    img = img[:, :, ::-1]\n",
        "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
        "    return img\n",
        "\n",
        "\n",
        "########################### main ###########################\n",
        "\n",
        "DATA_DIR = \"../data\"\n",
        "\n",
        "IMAGE_FILE = os.path.join(DATA_DIR, \"cat.jpg\")\n",
        "\n",
        "img = plt.imread(IMAGE_FILE)\n",
        "plt.imshow(img)\n",
        "img_copy = img.copy()\n",
        "print(\"Original image shape:\", img.shape)\n",
        "p_img = preprocess(img_copy)\n",
        "print(\"After preprocess:\", p_img.shape)\n",
        "d_img = deprocess(p_img)\n",
        "print(\"After deprocess:\", d_img.shape)\n",
        "plt.imshow(d_img)\n",
        "plt.show()\n",
        "\n",
        "# load pretrained VGG-16\n",
        "batch_shape = p_img.shape\n",
        "dream = Input(batch_shape=batch_shape)\n",
        "model = vgg16.VGG16(input_tensor=dream, weights=\"imagenet\", include_top=False)\n",
        "\n",
        "# create layer name to layer dictionary\n",
        "layer_dict = {layer.name : layer for layer in model.layers}\n",
        "#layer_dict\n",
        "\n",
        "# visualize gradients at pooling layers\n",
        "num_pool_layers = 5\n",
        "lr = 0.01\n",
        "fig, axes = plt.subplots(1, num_pool_layers, figsize=(20, 10))\n",
        "for i in range(num_pool_layers):\n",
        "    layer_name = \"block{:d}_pool\".format(i + 1)\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    loss = K.mean(layer_output)\n",
        "    grads = K.gradients(loss, dream)[0]\n",
        "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) * lr\n",
        "    f = K.function([dream], [loss, grads])\n",
        "    img_value = p_img.copy()\n",
        "    loss_value, grads_value = f([img_value])\n",
        "    axes[i].set_title(layer_name)\n",
        "    axes[i].imshow(deprocess(grads_value))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# deep dreaming\n",
        "first_layer = model.layers[-1]\n",
        "input_img = first_layer.input\n",
        "print(first_layer.name, first_layer.output_shape)\n",
        "\n",
        "num_pool_layers = 5\n",
        "num_iters_per_layer = 3\n",
        "step = 100\n",
        "\n",
        "for i in range(num_pool_layers):\n",
        "    layer_name = \"block{:d}_pool\".format(i+1)\n",
        "    print(\"Pooling Layer: {:s}\".format(layer_name))\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    # loss function\n",
        "    loss = K.mean(layer_output)\n",
        "    # gradient\n",
        "    grads = K.gradients(loss, dream)[0]\n",
        "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "    # optimizer\n",
        "    f = K.function([dream], [loss, grads])\n",
        "    img_value = p_img.copy()\n",
        "    fig, axes = plt.subplots(1, num_iters_per_layer, figsize=(20, 10))\n",
        "    for it in range(num_iters_per_layer):\n",
        "        loss_value, grads_value = f([img_value])\n",
        "        img_value += grads_value * step \n",
        "        axes[it].imshow(deprocess(img_value))\n",
        "    plt.show()\n",
        "\n",
        "# try to dream structure out of random noise\n",
        "img_noise = np.random.randint(100, 150, size=(227, 227, 3), dtype=np.uint8)\n",
        "print(img_noise.shape)\n",
        "plt.imshow(img_noise)\n",
        "plt.show()\n",
        "\n",
        "num_pool_layers = 5\n",
        "num_iters_per_layer = 3\n",
        "step = 100\n",
        "\n",
        "for i in range(num_pool_layers):\n",
        "    layer_name = \"block{:d}_pool\".format(i+1)\n",
        "    print(\"Pooling Layer: {:s}\".format(layer_name))\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    # loss function\n",
        "    loss = K.mean(layer_output)\n",
        "#     loss = layer_output[:,:,:,24]\n",
        "    # gradient\n",
        "    grads = K.gradients(loss, dream)[0]\n",
        "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "    # optimizer\n",
        "    f = K.function([dream], [loss, grads])\n",
        "    img_value = p_img.copy()\n",
        "    fig, axes = plt.subplots(1, num_iters_per_layer, figsize=(20, 10))\n",
        "    for it in range(num_iters_per_layer):\n",
        "        loss_value, grads_value = f([img_value])\n",
        "        img_value += grads_value * step \n",
        "        axes[it].imshow(deprocess(img_value))\n",
        "    plt.show()\n",
        "    \n",
        "# random noise with specific objective. Only do gradient ascent on\n",
        "# specific label and see that this pattern shows up\n",
        "num_pool_layers = 5\n",
        "num_iters_per_layer = 3\n",
        "step = 100\n",
        "\n",
        "for i in range(num_pool_layers):\n",
        "    layer_name = \"block{:d}_pool\".format(i+1)\n",
        "    print(\"Pooling Layer: {:s}\".format(layer_name))\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    # loss function\n",
        "    loss = layer_output[:,:,:,24]\n",
        "    # gradient\n",
        "    grads = K.gradients(loss, dream)[0]\n",
        "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "    # optimizer\n",
        "    f = K.function([dream], [loss, grads])\n",
        "    img_value = p_img.copy()\n",
        "    fig, axes = plt.subplots(1, num_iters_per_layer, figsize=(20, 10))\n",
        "    for it in range(num_iters_per_layer):\n",
        "        loss_value, grads_value = f([img_value])\n",
        "        img_value += grads_value * step \n",
        "        axes[it].imshow(deprocess(img_value))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMH-PujGpKLg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Style Transfer  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x9zdlJIfpIKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import division, print_function\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "from scipy.misc import imresize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess(img):\n",
        "    img4d = img.copy()\n",
        "    img4d = img4d.astype(\"float64\")\n",
        "    if K.image_dim_ordering() == \"th\":\n",
        "        # (H, W, C) -> (C, H, W)\n",
        "        img4d = img4d.transpose((2, 0, 1))\n",
        "    img4d = np.expand_dims(img4d, axis=0)\n",
        "    img4d = vgg16.preprocess_input(img4d)\n",
        "    return img4d\n",
        "\n",
        "def deprocess(img4d):\n",
        "    img = img4d.copy()\n",
        "    if K.image_dim_ordering() == \"th\":\n",
        "        # (B, C, H, W)\n",
        "        img = img.reshape((img4d.shape[1], img4d.shape[2], img4d.shape[3]))\n",
        "        # (C, H, W) -> (H, W, C)\n",
        "        img = img.transpose((1, 2, 0))\n",
        "    else:\n",
        "        # (B, H, W, C)\n",
        "        img = img.reshape((img4d.shape[1], img4d.shape[2], img4d.shape[3]))\n",
        "    img[:, :, 0] += 103.939\n",
        "    img[:, :, 1] += 116.779\n",
        "    img[:, :, 2] += 123.68\n",
        "    # BGR -> RGB\n",
        "    img = img[:, :, ::-1]\n",
        "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
        "    return img\n",
        "\n",
        "def content_loss(content, comb):\n",
        "    return K.sum(K.square(comb - content))\n",
        "\n",
        "def gram_matrix(x):\n",
        "    if K.image_dim_ordering() == \"th\":\n",
        "        features = K.batch_flatten(x)\n",
        "    else:\n",
        "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram\n",
        "\n",
        "def style_loss_per_layer(style, comb):\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(comb)\n",
        "    channels = 3\n",
        "    size = RESIZED_WH * RESIZED_WH\n",
        "    return K.sum(K.square(S - C)) / (4 * (channels ** 2) * (size ** 2))\n",
        "\n",
        "def style_loss():\n",
        "    stl_loss = 0.0\n",
        "    for i in range(NUM_LAYERS):\n",
        "        layer_name = \"block{:d}_conv1\".format(i+1)\n",
        "        layer_features = layer_dict[layer_name]\n",
        "        style_features = layer_features[1, :, :, :]\n",
        "        comb_features = layer_features[2, :, :, :]\n",
        "        stl_loss += style_loss_per_layer(style_features, comb_features)\n",
        "    return stl_loss / NUM_LAYERS\n",
        "\n",
        "def variation_loss(comb):\n",
        "    if K.image_dim_ordering() == \"th\":\n",
        "        dx = K.square(comb[:, :, :RESIZED_WH-1, :RESIZED_WH-1] - comb[:, :, 1:, :RESIZED_WH-1])\n",
        "        dy = K.square(comb[:, :, :RESIZED_WH-1, :RESIZED_WH-1] - comb[:, :, :RESIZED_WH-1, 1:])\n",
        "    else:\n",
        "        dx = K.square(comb[:, :RESIZED_WH-1, :RESIZED_WH-1, :] - comb[:, 1:, :RESIZED_WH-1, :])\n",
        "        dy = K.square(comb[:, :RESIZED_WH-1, :RESIZED_WH-1, :] - comb[:, :RESIZED_WH-1, 1:, :])\n",
        "    return K.sum(K.pow(dx + dy, 1.25))\n",
        "\n",
        "############################ main ############################\n",
        "\n",
        "DATA_DIR = \"../data\"\n",
        "\n",
        "CONTENT_IMAGE_FILE = os.path.join(DATA_DIR, \"cat.jpg\")\n",
        "STYLE_IMAGE_FILE = os.path.join(DATA_DIR, \"JapaneseBridgeMonetCopy.jpg\")\n",
        "\n",
        "RESIZED_WH = 400\n",
        "\n",
        "# verify that the content and style images are readable\n",
        "content_img_value = imresize(plt.imread(CONTENT_IMAGE_FILE), (RESIZED_WH, RESIZED_WH))\n",
        "style_img_value = imresize(plt.imread(STYLE_IMAGE_FILE), (RESIZED_WH, RESIZED_WH))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title(\"content\")\n",
        "plt.imshow(content_img_value)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"style\")\n",
        "plt.imshow(style_img_value)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# define content and style tensors\n",
        "content_img = K.variable(preprocess(content_img_value))\n",
        "style_img = K.variable(preprocess(style_img_value))\n",
        "if K.image_dim_ordering() == \"th\":\n",
        "    comb_img = K.placeholder((1, 3, RESIZED_WH, RESIZED_WH))\n",
        "else:\n",
        "    comb_img = K.placeholder((1, RESIZED_WH, RESIZED_WH, 3))\n",
        "\n",
        "# concatenate images into single input\n",
        "input_tensor = K.concatenate([content_img, style_img, comb_img], axis=0)\n",
        "input_tensor.get_shape()\n",
        "\n",
        "# download VGG16 model\n",
        "model = vgg16.VGG16(input_tensor=input_tensor,\n",
        "                   weights=\"imagenet\", include_top=False)\n",
        "\n",
        "layer_dict = {layer.name : layer.output for layer in model.layers}\n",
        "\n",
        "CONTENT_WEIGHT = 0.1\n",
        "STYLE_WEIGHT = 5.0\n",
        "VAR_WEIGHT = 0.01\n",
        "\n",
        "NUM_LAYERS = 5\n",
        "\n",
        "# define loss function as linear combination of content, style and variational\n",
        "# losses (defined above)\n",
        "c_loss = content_loss(content_img, comb_img)\n",
        "s_loss = style_loss()\n",
        "v_loss = variation_loss(comb_img)\n",
        "loss = (CONTENT_WEIGHT * c_loss) + (STYLE_WEIGHT * s_loss) + (VAR_WEIGHT * v_loss)\n",
        "\n",
        "grads = K.gradients(loss, comb_img)[0]\n",
        "f = K.function([comb_img], [loss, grads])\n",
        "\n",
        "NUM_ITERATIONS = 5\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "content_img4d = preprocess(content_img_value)\n",
        "for i in range(NUM_ITERATIONS):\n",
        "    print(\"Epoch {:d}/{:d}\".format(i+1, NUM_ITERATIONS))\n",
        "    loss_value, grads_value = f([content_img4d])\n",
        "    content_img4d += grads_value * LEARNING_RATE \n",
        "    plt.imshow(deprocess(content_img4d))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}