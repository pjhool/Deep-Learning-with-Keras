{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjhool/Deep-Learning-with-Keras/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BBP0SOnzG8AE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# StackGAN\n",
        "\n",
        "# https://arxiv.org/abs/1612.03242 \n",
        "# https://arxiv.org/abs/1511.06434 \n",
        "\n",
        "# Source Code   --> https://github.com/hanzhanggit/StackGAN-v2 \n",
        "\n",
        "\n",
        "# Youtube 강의  --> https://www.youtube.com/watch?v=odpjk7_tGY0 \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qNor6EVMJfFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1115
        },
        "outputId": "c273a92f-1398-4ce1-8b7e-bb255232fa5a"
      },
      "cell_type": "code",
      "source": [
        "!pip install papermill"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting papermill\n",
            "  Downloading https://files.pythonhosted.org/packages/87/a0/34888277b6d97d60c47ed4a09a1e7cc1beb169dcaacef48b9e838bf4cbb6/papermill-0.19.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from papermill) (0.22.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from papermill) (1.11.0)\n",
            "Collecting retry (from papermill)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/0d/53aea75710af4528a25ed6837d71d117602b01946b307a3912cb3cfcbcba/retry-0.9.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from papermill) (0.16.0)\n",
            "Requirement already satisfied: ipython>=5.0 in /usr/local/lib/python3.6/dist-packages (from papermill) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from papermill) (4.4.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from papermill) (0.3)\n",
            "Requirement already satisfied: nbconvert>=5.4 in /usr/local/lib/python3.6/dist-packages (from papermill) (5.4.1)\n",
            "Collecting tqdm>=4.29.1 (from papermill)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from papermill) (5.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from papermill) (2.18.4)\n",
            "Collecting ansiwrap (from papermill)\n",
            "  Downloading https://files.pythonhosted.org/packages/03/50/43e775a63e0d632d9be3b3fa1c9b2cbaf3b7870d203655710a3426f47c26/ansiwrap-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from papermill) (3.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from papermill) (7.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->papermill) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas->papermill) (1.14.6)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->papermill) (2.5.3)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.6/dist-packages (from retry->papermill) (4.3.2)\n",
            "Requirement already satisfied: py<2.0.0,>=1.4.26 in /usr/local/lib/python3.6/dist-packages (from retry->papermill) (1.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0->papermill) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0->papermill) (1.0.15)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0->papermill) (4.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0->papermill) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0->papermill) (40.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0->papermill) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0->papermill) (2.1.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->papermill) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->papermill) (4.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->papermill) (0.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.4->papermill) (2.10)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.4->papermill) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.4->papermill) (0.5.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.4->papermill) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.4->papermill) (0.4.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.4->papermill) (1.4.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->papermill) (17.0.0)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->papermill) (4.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->papermill) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->papermill) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->papermill) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->papermill) (1.22)\n",
            "Collecting textwrap3>=0.9.2 (from ansiwrap->papermill)\n",
            "  Downloading https://files.pythonhosted.org/packages/77/9c/a53e561d496ee5866bbeea4d3a850b3b545ed854f8a21007c1e0d872e94d/textwrap3-0.9.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0->papermill) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0->papermill) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert>=5.4->papermill) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.4->papermill) (0.5.1)\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: retry, tqdm, textwrap3, ansiwrap, papermill\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed ansiwrap-0.8.4 papermill-0.19.0 retry-0.9.2 textwrap3-0.9.2 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0G5roKuEIBnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "cellView": "code",
        "outputId": "94633862-427b-4e81-a073-0b646704bd87"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import math\n",
        "\n",
        "\n",
        "def generator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=100, output_dim=1024))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(128*7*7))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n",
        "    model.add(UpSampling2D(size=(2, 2)))\n",
        "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(UpSampling2D(size=(2, 2)))\n",
        "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_model():\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(\n",
        "                        64, 5, 5,\n",
        "                        border_mode='same',\n",
        "                        input_shape=(1, 28, 28)))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Convolution2D(128, 5, 5))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def generator_containing_discriminator(generator, discriminator):\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    discriminator.trainable = False\n",
        "    model.add(discriminator)\n",
        "    return model\n",
        "\n",
        "\n",
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[2:]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[0, :, :]\n",
        "    return image\n",
        "\n",
        "\n",
        "def train(BATCH_SIZE):\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
        "    discriminator = discriminator_model()\n",
        "    generator = generator_model()\n",
        "    discriminator_on_generator = \\\n",
        "        generator_containing_discriminator(generator, discriminator)\n",
        "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    discriminator_on_generator.compile(\n",
        "        loss='binary_crossentropy', optimizer=g_optim)\n",
        "    discriminator.trainable = True\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "    noise = np.zeros((BATCH_SIZE, 100))\n",
        "    for epoch in range(100):\n",
        "        print(\"Epoch is\", epoch)\n",
        "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
        "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
        "            for i in range(BATCH_SIZE):\n",
        "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
        "            generated_images = generator.predict(noise, verbose=0)\n",
        "            if index % 20 == 0:\n",
        "                image = combine_images(generated_images)\n",
        "                image = image*127.5+127.5\n",
        "                Image.fromarray(image.astype(np.uint8)).save(\n",
        "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
        "            d_loss = discriminator.train_on_batch(X, y)\n",
        "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
        "            for i in range(BATCH_SIZE):\n",
        "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "            discriminator.trainable = False\n",
        "            g_loss = discriminator_on_generator.train_on_batch(\n",
        "                noise, [1] * BATCH_SIZE)\n",
        "            discriminator.trainable = True\n",
        "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
        "            if index % 10 == 9:\n",
        "                generator.save_weights('generator', True)\n",
        "                discriminator.save_weights('discriminator', True)\n",
        "\n",
        "\n",
        "def generate(BATCH_SIZE, nice=False):\n",
        "    generator = generator_model()\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "    generator.load_weights('generator')\n",
        "    if nice:\n",
        "        discriminator = discriminator_model()\n",
        "        discriminator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
        "        discriminator.load_weights('discriminator')\n",
        "        noise = np.zeros((BATCH_SIZE*20, 100))\n",
        "        for i in range(BATCH_SIZE*20):\n",
        "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "        generated_images = generator.predict(noise, verbose=1)\n",
        "        d_pret = discriminator.predict(generated_images, verbose=1)\n",
        "        index = np.arange(0, BATCH_SIZE*20)\n",
        "        index.resize((BATCH_SIZE*20, 1))\n",
        "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
        "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
        "        nice_images = np.zeros((BATCH_SIZE, 1) +\n",
        "                               (generated_images.shape[2:]), dtype=np.float32)\n",
        "        for i in range(int(BATCH_SIZE)):\n",
        "            idx = int(pre_with_index[i][1])\n",
        "            nice_images[i, 0, :, :] = generated_images[idx, 0, :, :]\n",
        "        image = combine_images(nice_images)\n",
        "    else:\n",
        "        noise = np.zeros((BATCH_SIZE, 100))\n",
        "        for i in range(BATCH_SIZE):\n",
        "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
        "        generated_images = generator.predict(noise, verbose=1)\n",
        "        image = combine_images(generated_images)\n",
        "    image = image*127.5+127.5\n",
        "    Image.fromarray(image.astype(np.uint8)).save(\n",
        "        \"generated_image.png\")\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--mode\", type=str)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
        "    parser.add_argument(\"--nice\", dest=\"nice\", action=\"store_true\")\n",
        "    parser.set_defaults(nice=False)\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = get_args()\n",
        "    if args.mode == \"train\":\n",
        "        train(BATCH_SIZE=args.batch_size)\n",
        "    elif args.mode == \"generate\":\n",
        "        generate(BATCH_SIZE=args.batch_size, nice=args.nice)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "usage: ipykernel_launcher.py [-h] [--mode MODE] [--batch_size BATCH_SIZE]\n",
            "                             [--nice]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-728a831a-9e7b-46e8-9dfa-b062a38258d9.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}